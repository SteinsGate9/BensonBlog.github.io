<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.jpg?v=5.1.4">


  <link rel="mask-icon" href="/images/favicon.ico?v=5.1.4" color="#222">





  <meta name="keywords" content="numerical stats," />










<meta name="description" content="Stats Learning Theory Course Slides Notes">
<meta name="keywords" content="numerical stats">
<meta property="og:type" content="article">
<meta property="og:title" content="Statistical Learning Theory">
<meta property="og:url" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;index.html">
<meta property="og:site_name" content="BeNsoN">
<meta property="og:description" content="Stats Learning Theory Course Slides Notes">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;VqdvoazPSMInTQ2.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;OyqKboHkSQNDn75.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;HMS9BAGx8XZPTyQ.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;WEKaf4uoeIAlkc7.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jeljh2lj31c808wjt3.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jecq5rdj31cs0iuwgd.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;x7kQeKi8ybTrHwd.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123171055730.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;QrMq8YUoezv5lfF.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;nkh94C5FBHaPKdV.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123172003515.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191031153115435.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123172250177.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123172116906.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123173747296.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123173815260.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123174007296.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123174100478.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123172039645.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123173728461.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191031153310730.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;qYFxsHPloQND5w7.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;29vwoHBuIPEygGZ.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;3hfPieqtNvQcYol.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123174533026.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;31ckzfgGZ5vUaQm.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;QPOR4bGDZgHcIwM.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;WQcTBePXsGjtoEV.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123175242488.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123175306310.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lqs6o72j30p602kwem.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lrsn8ebj315g03iwes.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94o1xyvb9j30qq08g3zb.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94nwmwcxkj30rg04m3z2.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94o4i1hlkj30r001u0t2.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94nxbw79oj30ri02et8v.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qbhcivdj31570u07bt.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qc9fbg5j315u046aaj.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qc3sof4j316q046mya.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qcjj6jij315006aaaq.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qmpvb92j311e0bkmyh.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qpmgeaij317a0aajsy.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qpy0kq6j315k07wabg.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95ma9grqbj315c0bgwgb.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95maf8kpaj319a0f0wh3.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123175608269.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123175647270.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95oj97tgqj316008kq5h.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95ojr0phij315a0kggnt.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95ojwr4yzj315w04a0tq.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191023001520129.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191023001529332.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123181111001.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123181123718.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123181155391.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123181259373.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123181710201.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123231644429.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123231808572.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123231659159.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123231853530.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191031230308646.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124000519523.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124000830105.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124000859776.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124001145579.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124001241566.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124001251576.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124002128531.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124002405533.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124002546243.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124002702537.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124002717995.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124002833322.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124002856143.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124002908944.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124003023315.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124003119956.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191124003221119.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95ww91lpyj318u0p4ni8.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wwhbs4yj30o104iglz.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wxp8pjbj30pe0340u7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wxx4mb1j317o0bm49j.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wy58truj30zs0k816h.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wx02eexj30o5012t8l.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95r5on66nj316k04gwf6.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95r5wpu0mj317009275x.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95x6ig9taj30nu03tq38.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962lasmw3j319007y7bn.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962licechj318e05ogsc.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962lpaos0j31820c4jwn.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962veanruj30oo02at91.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962mdqdqvj318o07ygoz.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962mom5nrj30nw0fgt9n.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962nvb719j30oa01v3yj.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123132232152.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962o65ukwj30ox098gm9.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95pm0mzxxj31760iqaeu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95px5f6gjj317m0jgwip.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g96450i51uj30o305pab5.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123134507969.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964l986unj30ot0dm75n.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964li6gk5j30ny031aai.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964nsneufj30og02lt8y.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964pd0whnj30nv04ljrp.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964vbn2zuj30o40210su.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964vlz3hcj30og02gglt.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123231131104.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232017857.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232034601.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232045980.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232056701.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232108760.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232117823.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232241905.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232312620.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964pko8wij30ll03bjrf.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964r6bma5j30mv08w74u.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123141515437.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964rjujfgj30o703a74c.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232332935.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232347065.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123232359432.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964sdwcymj30o3060dg7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964ys8qbkj30od02zgm9.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964whyhyoj30n801j747.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123152755956.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123152820198.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964yzm3znj30og02fdg3.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123151349836.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123151358537.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123151407404.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964z6ewrbj30nh018aa2.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964zbzzkoj30oe047aaz.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964ziid51j30nx05daal.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191023091054642.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191031155626864.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191015161350400.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191023091839892.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191023091951058.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123121333880.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123121420040.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123121743529.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123121757398.png">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123122147883.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95npharqmj30ck04874b.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95o9tuhy7j315m07awg7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95o9zv0drj315y0560tu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95oaciywjj316y072wfk.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95nkp8b07j31660ekwhc.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95nlmbv8fj316k092jsx.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95o8uz3txj315u06qgna.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95olftvxlj316s0dqacl.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;image-20191123181529769.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;eJ6NBMAcbIR9mFO.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94uosvr98j30us09gt9p.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94uoljm4lj30v00emta4.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;Qpn3gXHzTPF2aZY.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94uo4jzd8j30uk030aak.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;tgpQOvDowBsfxHN.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;q68lQbYzNG9xjSs.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;NcJWjmECne4zbg1.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;5goRmWdDwpyv8hK.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;MtqP29VGAsvCU6B.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;VqbT2vfYJE9oSH3.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;zdSptJbWMUu9DQm.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;OzXTrZA4jmY9hVx.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94un7bhjsj30wc0byta5.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;HR7Fxa9ZECuMVeS.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;h8gfUSourM4qYQw.png">
<meta property="og:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;20&#x2F;MWp8JJ.png">
<meta property="og:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;20&#x2F;MWpAiQ.png">
<meta property="og:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;20&#x2F;MWpfw8.png">
<meta property="og:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;20&#x2F;MWpOmV.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;pzyisx7Ag5mFQGv.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;qVtT6Qz1an5b3mK.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94ume9k1hj30ts024a9y.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94ullkwx7j30w209qq4b.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;UbqFniyShgl627Y.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;Jg5KwYC4clsp1LO.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;SwgJqitobc2Xvku.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;IrRWNKDMTS9mn6l.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;Jg5KwYC4clsp1LO.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;WFjVfnO7pPeCmqd.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;H13oW6M2znwQlKY.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;ksrwUoluGiF7jMI.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;eJiRtwo5M9AEkDN.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;oYLf9tT3VOjEwUW.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;IyrRtMfzo4mJelU.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;Wbrua1oidJILVPp.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;8CZfKqxytmOoYih.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;WUvX9rTzie2xRn4.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kd7xe38j30sc024jrf.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kdj455cj30ok02q3ym.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kdp69btj30rs046aac.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kemgiihj30rk08gdgt.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kev03x5j30pg036t8v.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kfc3xu7j30ni03oq35.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94l67o489j314q088wgp.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94l6l7zfcj316e0380tf.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94llq6xidj315w03ct92.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lf89bzoj314a05gwey.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lfwvlcxj315607y0tg.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lgbmkh1j30wi03oglu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lgoido3j30y208oq3v.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lhpmmmmj316804wt9z.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94ljbz53fj316o02gt99.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94ljika20j317a0lon06.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jkwn25kj31d60hajuf.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jk8garjj31ca0ma79u.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jg6n3h0j31c20fgtbh.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jgg2rpcj317g0eutal.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95mj6tnn0j318o0640w1.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95mjwxpazj315y0dc0v5.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jox8hk9j311i0u042p.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jqrjkmjj315m084dh1.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jrlyyqij317c0a8q5c.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jrxmf2cj314i092wfg.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95kzuorryj313c0mwtbm.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95l02cd6kj31340mkdic.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95js9pkqkj316k08cq4q.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95l4x2rifj316a05ugml.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95l513c30j315i0f0q57.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jsuxibxj316205wgml.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95lgbda3bj319u0h6dj1.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95ldb2stkj31ac05g40g.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95m3zu4mkj316c054mxx.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95mln63k6j316407o3zu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95n9q6myzj30oc0dy0tu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95nakqg24j316i09cdi1.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95o80ulhcj315g0f643c.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jtgz619j31880kmad7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95luzezzcj31b00d0dml.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jtonm5mj316u0by0vb.jpg">
<meta property="og:updated_time" content="2019-11-29T07:01:53.289Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;VqdvoazPSMInTQ2.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: 'FV65T83Q2V',
      apiKey: '5008cf0478de4ac53102baceee722a4d',
      indexName: 'steinsgate9',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://SteinsGate9.github.io/2019/11/19/stats_theory/"/>





  <title>Statistical Learning Theory | BeNsoN</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/SteinsGate9" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">BeNsoN</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Live Long, Play Hard.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            About
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" target="_blank" rel="noopener" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://SteinsGate9.github.io/2019/11/19/stats_theory/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Benson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g96p07mbexj30uf0u0npd.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BeNsoN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Statistical Learning Theory</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-19T12:50:43+08:00">
                2019-11-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mathematics/" itemprop="url" rel="index">
                    <span itemprop="name">mathematics</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv">total read
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>times
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  3.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  18
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Stats Learning Theory Course Slides Notes</p>
<a id="more"></a>
<h1 id="generalized-expected-risk">1. generalized expected risk</h1>
<h2 id="learning-algorithm-loss-functions-1-1-3-1">1.1. learning algorithm &amp; loss functions (1-1, 3-1)</h2>
<p>f -&gt; h, L -&gt; R</p>
<ul>
<li><p><strong>Def</strong>: learning algorithm Ln (3-1)</p>
<p><strong>Usage</strong>: from data to algorithms space</p>
<p><img src="https://i.loli.net/2019/11/20/VqdvoazPSMInTQ2.png"></p>
<ul>
<li><p><strong>Def</strong>: weakly consistent / strongly consistent （3-1)</p>
<p><img src="https://i.loli.net/2019/11/20/OyqKboHkSQNDn75.png"></p>
<p><strong>Note</strong>: <span class="math inline">\(\hat{h_n}\)</span> is random variable since it completely depends on iid data when <span class="math inline">\(L_n\)</span> is fixed. (3-1)</p>
<p><img src="https://i.loli.net/2019/11/20/HMS9BAGx8XZPTyQ.png"></p></li>
</ul></li>
<li><p><strong>Def</strong>: loss (loss function) (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/WEKaf4uoeIAlkc7.png"></p>
<p><strong>Example</strong>: the relation of max likelihood &amp; loss function (1-10)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jeljh2lj31c808wjt3.jpg"></p>
<p><strong>Example</strong>: (1-10)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jecq5rdj31cs0iuwgd.jpg"></p></li>
</ul>
<h2 id="loss-functions">1.2. loss functions</h2>
<h3 id="e-f-loss-1-1-3-1">1.2.1. E-f-loss (1-1, 3-1)</h3>
<ul>
<li><p><strong>Def</strong>: E-f-loss (generalized expected risk) (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/x7kQeKi8ybTrHwd.png"></p>
<p>(3-1)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123171055730.png"></p></li>
<li><p><strong>Def</strong>: min-E-f-loss (minimal generalized expected risk) (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/QrMq8YUoezv5lfF.png"></p>
<ul>
<li><p><strong>Theorm</strong>: min-E-f-loss for binary classification is bayes classification</p>
<p>(1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/nkh94C5FBHaPKdV.png"></p>
<p>(3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123172003515.png"></p>
<p><img src="/2019/11/19/stats_theory/image-20191031153115435.png"></p>
<p><strong>Proof</strong>: (3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123172250177.png"></p></li>
<li><p><strong>Theorem</strong>: min-E-f-loss for binary classification(3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123172116906.png"></p>
<p><strong>Proof</strong>: (3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123173747296.png"></p>
<p><strong>Note</strong>:</p>
<p><img src="/2019/11/19/stats_theory/image-20191123173815260.png"></p></li>
<li><p><strong>Def</strong>: other form of bayes (3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123174007296.png"></p>
<p><strong>Note</strong>: figure of bayes risk (from 3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123174100478.png"></p></li>
<li><p><strong>Theorm</strong>: E-f-loss - min-E-f-loss (1-1, 3-1)</p>
<p><strong>Usage</strong>: find f to estimate f*</p>
<p>(3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123172039645.png"></p>
<p><strong>Proof</strong>:(3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123173728461.png"></p>
<p><strong>Note</strong>:(3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191031153310730.png"></p>
<p>(1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/qYFxsHPloQND5w7.png"></p>
<p><strong>Proof</strong>: (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/29vwoHBuIPEygGZ.png"></p></li>
</ul></li>
</ul>
<h3 id="e-f_hateta-loss-plug-in-classifiers-1-1-3-2">1.2.2. E-\(f_\hat{\eta}\)-loss (plug-in classifiers) (1-1, 3-2)</h3>
<ul>
<li><p><strong>Def</strong>: Plug-in classifier: swe can see that <span class="math inline">\(\eta\)</span> is what we what to estimate, the goal turns to find a better <span class="math inline">\(\eta\)</span>. (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/3hfPieqtNvQcYol.png"></p>
<p>(3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123174533026.png"></p></li>
<li><p><strong>Theorem</strong>: E-<span class="math inline">\(f_\hat{\eta}\)</span>-loss - min-E-f-loss (1-1)</p>
<p><strong>Usage</strong>: when using <span class="math inline">\(\hat{\eta}\)</span> to find best f, instead of directly finding f, what's the bound?</p>
<p>(1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/31ckzfgGZ5vUaQm.png"></p>
<p><strong>Proof</strong>: (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/QPOR4bGDZgHcIwM.png"></p>
<p><strong>Note</strong>: figure / pros &amp; cons to use <span class="math inline">\(\hat{\eta}\)</span> to minimize E loss (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/WQcTBePXsGjtoEV.png"></p>
<p>(3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123175242488.png"></p>
<p><strong>Note</strong>: (3-2)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123175306310.png"></p></li>
</ul>
<h3 id="e-f-newloss-1-6-1-7">1.2.3. E-f-newloss (1-6, 1-7)</h3>
<ul>
<li><p><strong>Def</strong>: E-f-newloss</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lqs6o72j30p602kwem.jpg"></p>
<p><strong>Note</strong>: SVM</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lrsn8ebj315g03iwes.jpg"></p>
<ul>
<li><p><strong>Qua</strong>: =&gt; elaboration</p>
<p><strong>Usage</strong>: we can minimize E-f-newloss by minimizing the follows at every x/</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94o1xyvb9j30qq08g3zb.jpg"></p></li>
<li><p><strong>Def</strong>: new elements to compute min-E-f-newloss, <span class="math inline">\(H(\eta)\)</span> means the lowest point of all f, all x.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94nwmwcxkj30rg04m3z2.jpg"></p>
<p><strong>Note</strong>: SVM</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94o4i1hlkj30r001u0t2.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94nxbw79oj30ri02et8v.jpg"></p></li>
<li><p><strong>Qua</strong>: when <span class="math inline">\(\phi\)</span> is convex =&gt; <span class="math inline">\(H ^{-}(\eta) =\phi(0)\)</span></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qbhcivdj31570u07bt.jpg"></p></li>
<li><p><strong>Def</strong>: classification - calibrated</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qc9fbg5j315u046aaj.jpg"></p>
<p><strong>Example</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qc3sof4j316q046mya.jpg"></p>
<ul>
<li><p><strong>Qua</strong>: necc &amp; suff<img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qcjj6jij315006aaaq.jpg"></p>
<p><strong>Proof</strong>: too long</p></li>
<li><p><strong>Qua</strong>: real gap is bounded by E-f-newcalibratedloss</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qmpvb92j311e0bkmyh.jpg"></p>
<p><strong>Proof</strong>: too long</p>
<p><strong>Example</strong>: in the case of SVM, <span class="math inline">\(\phi\)</span> is a given convex function, therefore we can conpute <span class="math inline">\(H(\phi)\)</span> and yield a upper bound for the real gap. which means when training performs good, the result will most likely be the same.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qpmgeaij317a0aajsy.jpg"></p>
<p><strong>Example</strong>: adaboost is the same, <span class="math inline">\(\phi(a)\)</span> is convex and we can again use theorem 2.2</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qpy0kq6j315k07wabg.jpg"></p>
<p><strong>Example</strong>: adaboost(1-13), a more detailed explaination, <span class="math inline">\(\phi\)</span> is class-calibrated, so we can use theorem 2.2.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95ma9grqbj315c0bgwgb.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95maf8kpaj319a0f0wh3.jpg"></p></li>
</ul></li>
</ul></li>
</ul>
<h3 id="em-f-loss-1-213-3-345">1.2.4. Em-f-loss (1-2,13, 3-3,4,5)</h3>
<h4 id="em-f-loss">1.2.4.1. Em-f-loss</h4>
<ul>
<li><p><strong>Def</strong>: Em-f-loss</p>
<p>(3-3)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123175608269.png"></p>
<p><strong>Note</strong>: (3-3)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123175647270.png"></p>
<ul>
<li><p><strong>Qua</strong>: Em-f-loss converge to E-f-loss (1-13)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95oj97tgqj316008kq5h.jpg"></p>
<p><strong>Proof</strong>: why E(empirical risk) = generalized : E(h) is actually P(y|x), so $E((h))=_n E(1(...))/n=_n p/n = p $</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95ojr0phij315a0kggnt.jpg"></p>
<p><strong>Note</strong>: (1-13)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95ojwr4yzj315w04a0tq.jpg"></p></li>
</ul></li>
</ul>
<h5 id="uniform-deviation-bound">1.2.4.1.1. uniform deviation bound</h5>
<ul>
<li><p><strong>Theorm</strong>:: =&gt; Em-f-loss - E-f-loss, uniform deviation bound (bound the performance of em)(not know h)(3-4)</p>
<p><img src="/2019/11/19/stats_theory/image-20191023001520129.png"></p>
<p><strong>Proof</strong>: (3-4)</p>
<p><img src="/2019/11/19/stats_theory/image-20191023001529332.png"></p>
<p><strong>note</strong>:</p>
<p><img src="/2019/11/19/stats_theory/image-20191123181111001.png"></p></li>
<li><p><strong>Theorm</strong>: =&gt; Em-f-loss bound case 2 unifrom devia bound (3-4)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123181123718.png"></p>
<p><strong>Note</strong>:(3-4)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123181155391.png"></p></li>
<li><p><strong>Theorm</strong>: =&gt; Em-f-loss probability bound2 (3-4)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123181259373.png"></p></li>
<li><p><strong>Theorem</strong> =&gt; Em-f-loss bound 3, if zero error case (3-4)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123181710201.png"></p></li>
</ul>
<h5 id="vc-bound">1.2.4.1.2. vc bound</h5>
<ul>
<li><p><strong>Theorm</strong>:: =&gt; vc bound 4 (3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123231644429.png"></p>
<p><strong>Note</strong>: that the right side can be bounded</p>
<p><img src="/2019/11/19/stats_theory/image-20191123231808572.png"></p>
<ul>
<li><p><strong>Corollary</strong>:</p>
<p><img src="/2019/11/19/stats_theory/image-20191123231659159.png"></p>
<p><strong>Proof</strong>: follows from theorem using an argument like that when <span class="math inline">\(|H|&lt; \infty\)</span></p></li>
<li><p><strong>Corollary</strong>: this is obvious from theorem.</p>
<p><img src="/2019/11/19/stats_theory/image-20191123231853530.png"></p></li>
</ul></li>
<li><p><strong>Theorm</strong>: =&gt; learnable (3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191031230308646.png"></p></li>
</ul>
<h5 id="bound-improvement-by-approximation-error">1.2.4.1.3. bound improvement by approximation error</h5>
<h6 id="uap-approximate-error">1.2.4.1.3.1. UAP &amp; approximate error</h6>
<ul>
<li><p><strong>Intro</strong>: decomposition to est ( discussed in above, basically random) + app ( not discussed before, decide by algorithm pool H). In this lecture we'll talk about app error (3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124000519523.png"></p>
<p><strong>Def</strong>: universal approximation property (3-6)</p>
<p><strong>Usage</strong>: UAP is when H pool grows, the approximation error converge to 0.</p>
<p><img src="/2019/11/19/stats_theory/image-20191124000830105.png"></p>
<p><strong>Note</strong>:(3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124000859776.png"></p>
<ul>
<li><p><strong>Theorem</strong>: special Hk consist of piecewise constant classifiers =&gt; (3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124001145579.png"></p>
<p><strong>Example</strong>:(3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124001241566.png"></p>
<p><img src="/2019/11/19/stats_theory/image-20191124001251576.png"></p></li>
</ul></li>
</ul>
<h6 id="sieve-estimators">1.2.4.1.3.2. sieve estimators</h6>
<ul>
<li><p><strong>Def</strong>: best estimate classifier from H (3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124002128531.png"></p></li>
<li><p><strong>Intro &amp; Def</strong>:Strong Universally Consistent, why and what is a sieve estimator, basically to let the whole thing go to 0 simutaniously. (3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124002405533.png"></p>
<ul>
<li><p><strong>Theorem</strong>: UAP &amp; k(n) sequence =&gt; (3-6)<img src="/2019/11/19/stats_theory/image-20191124002546243.png"></p>
<p><strong>Proof</strong>: (3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124002702537.png"></p>
<ul>
<li><p><strong>Corollary</strong>: similar to theorem =&gt; (3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124002717995.png"></p>
<p><strong>Note</strong>: (3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124002833322.png"></p></li>
</ul></li>
<li><p><strong>Theorem</strong>: UAP + VC bound =&gt; (3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124002856143.png"></p>
<p><strong>Proof</strong>:(3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124002908944.png"></p></li>
</ul></li>
</ul>
<h6 id="rate-of-convergence">1.2.4.1.3.3. rate of convergence</h6>
<ul>
<li><p><strong>Def</strong>: rate of convergence(3-6)<img src="/2019/11/19/stats_theory/image-20191124003023315.png"></p>
<ul>
<li><p><strong>Theorem</strong>:(3-6)<img src="/2019/11/19/stats_theory/image-20191124003119956.png"></p>
<p><strong>Note</strong>:(3-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191124003221119.png"></p>
<p><strong>Example</strong>: box-counting class (3-6)</p></li>
</ul></li>
</ul>
<h4 id="empirical-processing-theory">1.2.4.2. empirical processing theory</h4>
<p><strong>Goal</strong>: to make Em &amp; E close enough</p>
<p>Empirical Process theory allows us to prove uniform convergence laws of various kinds. One of the ways to start Empirical Process theory is from the Glivenko-Cantelli theorem. This leads to the question of whether the same idea can be generalized to other function classes.</p>
<h5 id="glivenko-cantelli">1.2.4.2.1. Glivenko-Cantelli</h5>
<p>This is where we'll start, by proving GC and go further.</p>
<h6 id="empirical-distribution-function-book-2-2">1.2.4.2.1.1. empirical distribution function (book, 2-2)</h6>
<ul>
<li><p><strong>Def</strong>: empirical distribution function</p>
<p>(book)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95ww91lpyj318u0p4ni8.jpg"></p>
<p>(2-2)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wwhbs4yj30o104iglz.jpg"></p>
<ul>
<li><p><strong>Qua</strong>: =&gt; is a statistic (book)</p></li>
<li><p><strong>Qua</strong>: =&gt; range (book)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wxp8pjbj30pe0340u7.jpg"></p></li>
<li><p><strong>Qua</strong>: =&gt; other interpretation(book)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wxx4mb1j317o0bm49j.jpg"></p></li>
<li><p><strong>Qua</strong>: =&gt; limits (book)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wy58truj30zs0k816h.jpg"></p>
<p>(2-2)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wx02eexj30o5012t8l.jpg"></p></li>
</ul></li>
</ul>
<h6 id="gc-class-theory-1-16-2-2">1.2.4.2.1.2. GC class &amp; theory (1-16, 2-2)</h6>
<ul>
<li><p><strong>Def</strong>: GC class (1-16)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95r5on66nj316k04gwf6.jpg"></p></li>
<li><p><strong>Theorem</strong>: GC theory</p>
<p>(1-16)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95r5wpu0mj317009275x.jpg"></p>
<p>(2-2)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95x6ig9taj30nu03tq38.jpg"></p>
<p>(book)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962lasmw3j319007y7bn.jpg"></p>
<p><strong>Note</strong>: Fn and F is very close when n is large</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962licechj318e05ogsc.jpg"></p></li>
</ul>
<h5 id="symmetrization-lemma-2-5">1.2.4.2.2. symmetrization lemma (2-5)</h5>
<p>Lemma in this section is important to generalize GC.</p>
<ul>
<li><p><strong>Def</strong> : recall distribution function (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962lpaos0j31820c4jwn.jpg"></p></li>
<li><p><strong>Def</strong>: Rademacher variables (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962veanruj30oo02at91.jpg"></p></li>
<li><p><strong>Lemma</strong>: =&gt; first symmtry bound the Fn-F(t) (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962mdqdqvj318o07ygoz.jpg"></p>
<p><strong>Usage</strong>: using two indenpendent stochastic process to set upper bound for one .</p>
<p><strong>Example</strong>: (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962mom5nrj30nw0fgt9n.jpg"></p></li>
<li><p><strong>Lemma</strong>: second symmtry =&gt; aallowsustoreplacethedifferenceFn−Fn′ withasingleempiricalquantity consisting of n observations. We can further bound the latter so that the bound is independent of the data ξ. (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962nvb719j30oa01v3yj.jpg"></p>
<p><strong>Usage</strong>：using independent variables to set upper bound for GC (2-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123132232152.png"></p>
<p><strong>Proof</strong>: (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962o65ukwj30ox098gm9.jpg"></p></li>
</ul>
<h5 id="uniform-convergence-uniform-law-of-large-numbers-1-1314-2-6">1.2.4.2.3. uniform convergence &amp; uniform law of large numbers (1-13,14, 2-6)</h5>
<p>Using Lemma above to prove GC</p>
<p><strong>Goal</strong>: for every F, make Em &amp; E close enough. we can first generalize the Glivenko-Cantelli theorem (a special F space).</p>
<ul>
<li><p><strong>Intro</strong>: what is and why we should use uniform convergence: (1-13, 1-14)</p>
<p>if there's only one function in F, we simply use law of large numbers, then we can prove convergence, but it is of no use.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95pm0mzxxj31760iqaeu.jpg"></p>
<p><strong>Example</strong>: when F contains more functions and here the case is when dataset are separated, empirical risk are sometimes not convergence to real risk. (1-13)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95px5f6gjj317m0jgwip.jpg"></p>
<p><strong>Example</strong>: the GC theorem in function way (2-6)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g96450i51uj30o305pab5.jpg"></p></li>
<li><p><strong>Intro</strong>: using <strong>Lemma</strong>1 in 1.2.3.2.3 to empirical functions (2-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123134507969.png"></p>
<p><strong>Usage</strong>: when we F specialize to indicators (2-6)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964l986unj30ot0dm75n.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964li6gk5j30ny031aai.jpg"></p></li>
</ul>
<p>​</p>
<h5 id="vc-class-and-stuff">1.2.4.2.4. vc class and stuff</h5>
<p>Vc &amp; covering number are powerful tools to empirical learning.</p>
<p>######vc class (2-6,7, 3-5)</p>
<ul>
<li><p><strong>Def</strong>: vc class</p>
<p><strong>Usage</strong>: vc class , C is a collection of sets，X is the largest set, Vc is：given n points from X, if subsets of C cannot separate X into <span class="math inline">\(2 ^{n}\)</span> parts，then <span class="math inline">\(V ^{C}=n\)</span>, mind that we should go from n =1 to above, and see if we could find the x points that could be shattered by this set, if not we shop and set Vc = n. So basically, the larger Vc, the better C is in regards to shatting set X.</p>
<p>(2-6)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964nsneufj30og02lt8y.jpg"></p>
<p><strong>Example</strong>: $V ^{C} = 2 $ since given <span class="math inline">\(x1=1, x2=2\)</span>, you can't separate them. (2-6)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964pd0whnj30nv04ljrp.jpg"></p>
<p><strong>Example</strong>: half space (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964vbn2zuj30o40210su.jpg"></p>
<p><strong>Example</strong>: subgraph (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964vlz3hcj30og02gglt.jpg"></p>
<p>(3-5), nth shatter coeffcient is m(n), for all n &lt; Vc, we say F/H shatters {x1...xn}</p>
<p><img src="/2019/11/19/stats_theory/image-20191123231131104.png"></p>
<p><strong>Example</strong>: (3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123232017857.png"></p>
<p><img src="/2019/11/19/stats_theory/image-20191123232034601.png"></p>
<p><img src="/2019/11/19/stats_theory/image-20191123232045980.png"></p>
<p><strong>Example</strong>: (3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123232056701.png"></p>
<p><strong>Example</strong>: (3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123232108760.png"></p>
<p><img src="/2019/11/19/stats_theory/image-20191123232117823.png"></p>
<ul>
<li><p><strong>Lemma</strong>: =&gt; bound Vc for a broad family of classes</p>
<p><img src="/2019/11/19/stats_theory/image-20191123232241905.png"></p></li>
<li><p><strong>Lemma</strong>: =&gt; Sauer's the relation ship between m(n) and Vc</p>
<p>(3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123232312620.png"></p>
<p>(2-6)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964pko8wij30ll03bjrf.jpg"></p>
<p><strong>Proof</strong>: (2-6)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964r6bma5j30mv08w74u.jpg"></p>
<p><strong>Note</strong>: that we can use VC to see Pn, use m(n) to indicate the <span class="math inline">\(2 ^{n}\)</span> subsets of all, and we use lemma to get a upper bound of Pn0 (2-6)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123141515437.png"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964rjujfgj30o703a74c.jpg"></p>
<ul>
<li><p><strong>Corollary</strong>: (3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123232332935.png"></p></li>
<li><p><strong>Corollary</strong>: (3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123232347065.png"></p></li>
<li><p><strong>Corollary</strong>: (3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123232359432.png"></p></li>
</ul></li>
<li></li>
<li><p><strong>Qua</strong>: operation (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964sdwcymj30o3060dg7.jpg"></p></li>
</ul></li>
</ul>
<p>​</p>
<h6 id="covering-number-2-7-2-8">1.2.4.2.4.1. covering number (2-7, 2-8)</h6>
<ul>
<li><p><strong>Def</strong>: covering number (a more powerful way than VC) (2-7)</p>
<p><strong>Usage</strong>: a covering number is the smallest number of functions that can approximate any f with metric Q in F. Apparently larger N1, the more complex class F, the more powerful it is in regards to classification. Here N1 means F is constrained within <span class="math inline">\(L ^{1}(Q)\)</span></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964ys8qbkj30od02zgm9.jpg"></p>
<p><strong>Note</strong>: not unique s (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964whyhyoj30n801j747.jpg"></p>
<ul>
<li><p><strong>Theorem</strong>: =&gt; apporximation lemma, giving an upper bound for covering number of VC dimension(2-8)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123152755956.png"></p>
<p><strong>Usage</strong>: (2-8)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123152820198.png"></p></li>
</ul></li>
</ul>
<h6 id="entropy">1.2.4.2.4.2. entropy</h6>
<ul>
<li><p><strong>Def</strong>: metric entropy (2-7)</p>
<p><strong>Usage</strong>: metric entropy is log N1.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964yzm3znj30og02fdg3.jpg"></p>
<p><strong>Example</strong>: (2-7)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123151349836.png"></p>
<p><strong>Proof</strong>: computing cover number for F. Using definition of covering number, constructing <span class="math inline">\(\hat{f}\)</span> for F (2-7)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123151358537.png"></p>
<p><img src="/2019/11/19/stats_theory/image-20191123151407404.png"></p>
<ul>
<li><p><strong>Def</strong>: totally bounded (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964z6ewrbj30nh018aa2.jpg"></p></li>
</ul></li>
<li><p><strong>Def</strong>: entropy with bracking (2-7)</p>
<p><strong>Usage</strong>: Np,B means the smallest of m pairs of functions that can approximate any f in F.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964zbzzkoj30oe047aaz.jpg"></p></li>
<li><p><strong>Qua</strong>: relation of metric &amp; brackeing entropy (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964ziid51j30nx05daal.jpg"></p></li>
</ul>
<h6 id="vc-theory-for-sets3-5">1.2.4.2.4.3. vc theory for sets(3-5)</h6>
<ul>
<li><p><strong>Theorm</strong>: VC theory =&gt; convergence guarantees for an empirical risk minimizing classifier when the VC dimen- sion of the classifier set H was finite. (3-5)</p>
<p><img src="/2019/11/19/stats_theory/image-20191023091054642.png"></p>
<ul>
<li><p><strong>Corollary</strong> DKW</p>
<p><img src="/2019/11/19/stats_theory/image-20191031155626864.png"></p></li>
</ul></li>
<li><p><strong>Qua</strong>: operation.</p>
<p><img src="/2019/11/19/stats_theory/image-20191015161350400.png"></p></li>
</ul>
<h6 id="mono-layer-a-special-classifier3-5">1.2.4.2.4.4. mono layer (a special classifier)(3-5)</h6>
<ul>
<li><p><strong>Def</strong>: see page 8 of class_3 lecture 5</p>
<ul>
<li><p><strong>Theorm</strong>: =&gt; bound of expected shatter coefficient</p>
<p><img src="/2019/11/19/stats_theory/image-20191023091839892.png"></p>
<ul>
<li><p><strong>Corollary</strong>: =&gt; convergence</p>
<p><img src="/2019/11/19/stats_theory/image-20191023091951058.png"></p></li>
</ul></li>
</ul></li>
</ul>
<h5 id="p-glivenko-cantelli-for-class-f">1.2.4.2.5. P-Glivenko-Cantelli (for class F)</h5>
<p>This is where we finally arrived at, the generalized GC.</p>
<ul>
<li><p><strong>Def</strong>: P-Glivenko-Cantelli class(2-8)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123121333880.png"></p></li>
<li><p><strong>Def</strong>: envelop (2-8)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123121420040.png"></p>
<ul>
<li><p><strong>Theorem</strong>: =&gt; P-GC (2-8)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123121743529.png"></p>
<p><strong>Note</strong>: intuition for condition of metric entropy (2-8)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123121757398.png"></p>
<p><strong>Proof</strong>: way too long</p>
<p><strong>Example</strong>: (2-8)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123122147883.png"></p></li>
</ul></li>
</ul>
<h2 id="alternative-goals">1.3. alternative goals</h2>
<h3 id="maximum-likelihood">1.3.1. maximum likelihood</h3>
<ul>
<li><p><strong>Def</strong>: maximum likelihood</p>
<p><strong>Usage</strong>: turn to an alternative minimization goal</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95npharqmj30ck04874b.jpg" style="zoom:33%;"></p></li>
</ul>
<h3 id="probably-approximately-correct-1-13-3-4">1.3.2. probably approximately correct (1-13, 3-4)</h3>
<ul>
<li><p><strong>Def</strong>: PAC (1-13)</p>
<p><strong>Usage</strong>: turn to an alternative goal.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95o9tuhy7j315m07awg7.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95o9zv0drj315y0560tu.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95oaciywjj316y072wfk.jpg"></p>
<p>​</p>
<ul>
<li><p><strong>Def</strong>: probability approximate corret condition (1-13)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95nkp8b07j31660ekwhc.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95nlmbv8fj316k092jsx.jpg"></p></li>
<li><p><strong>Qua</strong>: PAC insights (1-13)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95o8uz3txj315u06qgna.jpg"></p></li>
<li><p><strong>Def</strong>: PAC learnable (1-13)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95olftvxlj316s0dqacl.jpg"></p></li>
</ul></li>
<li><p><strong>Def</strong>: PAC definition 2 ( 3-4)</p>
<p><img src="/2019/11/19/stats_theory/image-20191123181529769.png"></p></li>
</ul>
<p>#perceptron algorithm</p>
<h2 id="perceptron-algorithim">1.4. perceptron algorithim</h2>
<ul>
<li><p><strong>Def</strong>: The perceptron algorithm performs pattern classification when F is the class of linear threshold functions.</p>
<p><img src="https://i.loli.net/2019/11/20/eJ6NBMAcbIR9mFO.png"></p>
<p><strong>Algo</strong>: algorithm of perceptron</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94uosvr98j30us09gt9p.jpg"></p>
<p><strong>Note</strong>: figure of perceptron</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94uoljm4lj30v00emta4.jpg"></p></li>
<li><p><strong>Theorem</strong>: complexity of the algorithm to converge.</p>
<p><strong>Usage</strong>: result gives a bound on the number of steps in terms of some properties of the data.</p>
<p><img src="https://i.loli.net/2019/11/20/Qpn3gXHzTPF2aZY.png"></p>
<p><strong>Proof</strong>: too long</p>
<p><strong>Note</strong>: perceptron complexity may not be linear, it is possible it do not terminate after a long time</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94uo4jzd8j30uk030aak.jpg"></p>
<ul>
<li><p><strong>Qua</strong>: One important feature of this algorithm is that it only uses inner products of the data points.</p>
<p>The update step of the algorithm produces a wt which is a linear combination of the xi, so we write it as <span class="math inline">\(wt = 􏰐nj=1 αjxj\)</span> for <span class="math inline">\(αj ∈ R\)</span> and <span class="math inline">\(∥α∥1 = 􏰐nj=1 |αj| ≤ t\)</span>. For this choice of <span class="math inline">\(w t\)</span>, the prediction rule becomes</p></li>
</ul></li>
<li><p><span class="math display">\[
  \hat{y}_i = sign(w_t ^{T}x _{i}) = sign( \sum_{j}^{}a _{j}x _{j} ^{T} x _{i})
\]</span></p>
<p>updates become (i is one of the misclassified points) <span class="math display">\[
a _{i} ^{(t+1)} = a _{i} ^{(t)} + y _{i}
\]</span> <img src="https://i.loli.net/2019/11/20/tgpQOvDowBsfxHN.png"></p>
<p><strong>Note</strong>: from this quality we can see the inspiration of kernel, that we only need the inner product of xixj, with the quality of readiness of computing inner product after projection, we can use kernel to get a more complex model</p>
<p><img src="https://i.loli.net/2019/11/20/q68lQbYzNG9xjSs.png"></p></li>
<li><p><strong>Lemma</strong>: linearly independent =&gt; seperatable data</p>
<p><img src="https://i.loli.net/2019/11/20/NcJWjmECne4zbg1.png"></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://i.loli.net/2019/11/20/5goRmWdDwpyv8hK.png"></p>
<ul>
<li><strong>Theorem</strong> : The main theorem in this section shows that for any prediction rule (from the class of linear threshold functions), there is a probability distribution that is linearly separable, but for which the prediction rule does poorly when averaged over all training data sets.</li>
</ul>
<p><strong>Usage</strong>: we can compute this lower bound, to estimate the risk for this threshold function.</p>
<p><img src="https://i.loli.net/2019/11/20/MtqP29VGAsvCU6B.png"></p>
<p><strong>Proof</strong>: too long</p>
<p><strong>Note</strong> 1: see this bound as minimax lower bound, meaning that whatever <span class="math inline">\(f _{n}\)</span> you choose, there exists some part of the training dataset that yield result with lower bound.</p>
<p><img src="https://i.loli.net/2019/11/20/VqbT2vfYJE9oSH3.png"></p>
<p><strong>Note</strong> 2: generalization using VC dimension.</p>
<p><img src="https://i.loli.net/2019/11/20/zdSptJbWMUu9DQm.png"></p>
<ul>
<li><p><strong>Theorem</strong>: If we restrict our attention to probability distributions that have a large margin, we can prove an upper bound for the risk of the perceptron algorithm:</p>
<p><img src="https://i.loli.net/2019/11/20/OzXTrZA4jmY9hVx.png"></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94un7bhjsj30wc0byta5.jpg"></p></li>
<li><p><strong>Theorm</strong>: In the above theorem, we were maximizing over all probability distributions. If we restrict the maximization to be over those probability distributions having a large margin we can obtain a better lower bound:</p>
<p><img src="https://i.loli.net/2019/11/20/HR7Fxa9ZECuMVeS.png"></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://i.loli.net/2019/11/20/h8gfUSourM4qYQw.png"></p></li>
</ul></li>
</ul>
<h2 id="support-vector-machine">1.5. support vector machine</h2>
<h3 id="basic-svm">1.5.1. basic SVM</h3>
<ul>
<li><p><strong>Def</strong>: support vector machine</p>
<p><strong>Usage</strong>: special form of perceptron where the distance is maximized</p>
<figure>
<img src="https://s2.ax1x.com/2019/11/20/MWp8JJ.png" alt><figcaption>MWp8JJ.png</figcaption>
</figure>
<p><strong>Note</strong>:</p>
<p><img src="https://s2.ax1x.com/2019/11/20/MWpAiQ.png" alt="MWpAiQ.png" style="zoom:89%;"></p>
<ul>
<li><p><strong>Qua</strong>: basic transformations</p>
<p>trans: other form <span class="math inline">\(\left \| w\right \|=1\)</span></p>
<figure>
<img src="https://s2.ax1x.com/2019/11/20/MWpfw8.png" alt><figcaption>MWpfw8.png</figcaption>
</figure>
<p>trans: other form <span class="math inline">\(\left \| w\right \|=1/ \gamma\)</span></p>
<figure>
<img src="https://s2.ax1x.com/2019/11/20/MWpOmV.png" alt><figcaption>MWpOmV.png</figcaption>
</figure>
<p>lagrange function</p>
<p><img src="https://i.loli.net/2019/11/20/pzyisx7Ag5mFQGv.png"></p>
<p>get lagrange dual function</p>
<p><img src="https://i.loli.net/2019/11/20/qVtT6Qz1an5b3mK.png"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94ume9k1hj30ts024a9y.jpg"></p>
<p>interpret lagrange function</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94ullkwx7j30w209qq4b.jpg"></p>
<p>lagrange dual function</p>
<p><img src="https://i.loli.net/2019/11/20/UbqFniyShgl627Y.png"></p>
<p>dual problem</p>
<p><img src="https://i.loli.net/2019/11/20/Jg5KwYC4clsp1LO.png"></p>
<p>recall slackenss for dual problem, this show that the those with ai(penalty loss) <span class="math inline">\(\neq\)</span> 0, are exactly those in the margins.</p>
<p><img src="https://i.loli.net/2019/11/20/SwgJqitobc2Xvku.png"></p>
<p>recall the kernel stuff, we can use kernel to efficientlly solve this, for more kernel stuff turn to 2.2.2</p>
<p><img src="https://i.loli.net/2019/11/20/IrRWNKDMTS9mn6l.png"></p></li>
</ul></li>
</ul>
<h3 id="kernel-svm">1.5.2. kernel SVM</h3>
<ul>
<li><p><strong>Def</strong>: dual problem &amp; kernel function</p>
<p>dual problem (only inner products determines solution) <img src="https://i.loli.net/2019/11/20/Jg5KwYC4clsp1LO.png"></p>
<ul>
<li><p><strong>Qua</strong>: kernel function can reduce complexity of dual problem.( further discussion can be find in linera algebra)</p>
<p><strong>Usage</strong>: 由此看出，即使没有kernel，只要找到映射关系，我们仍然可以实现低维空间映射到高维空间，进而通过高维向量内积运算来寻找最佳分割超平面。但是，kernel的引入，降低了向量内积运算的计算复杂度。无论我们映射到几维空间，我们只要把原有维度代入核函数，就能等价于高维上的内积运算。极端的情况下，特征空间映射到了无穷维度空间，如果没有核函数，根本无法计算出映射后的向量内积。</p>
<p>（映射到新的特征空间后的内积=原空间核函数）</p>
<p>https://blog.csdn.net/zhangjun2915/article/details/79261368</p>
<p>k(xi, xj) is the kernel function of inner product of xi, xj</p></li>
<li><p><strong>Example</strong>: polynomial kernel</p>
<p><img src="https://i.loli.net/2019/11/20/WFjVfnO7pPeCmqd.png"></p></li>
<li><p><strong>Example</strong>: gaussian kernel</p>
<p><img src="https://i.loli.net/2019/11/20/H13oW6M2znwQlKY.png"></p></li>
</ul></li>
</ul>
<h3 id="primal-svm">1.5.3. primal SVM</h3>
<ul>
<li><p><strong>Def</strong>: primal SVM, more natural way</p>
<p><img src="https://i.loli.net/2019/11/20/ksrwUoluGiF7jMI.png"></p>
<p>lagrangian functiion</p>
<p><img src="https://i.loli.net/2019/11/20/eJiRtwo5M9AEkDN.png"></p>
<p>getting lagranian dual function</p>
<p><img src="https://i.loli.net/2019/11/20/oYLf9tT3VOjEwUW.png"></p>
<p>lagrangain dual function</p>
<p><img src="https://i.loli.net/2019/11/20/IyrRtMfzo4mJelU.png"></p>
<p>dual problem</p>
<p><img src="https://i.loli.net/2019/11/20/Wbrua1oidJILVPp.png"></p>
<p>this problem can actually be solved by hand: first solve <span class="math inline">\(\beta = \sqrt{1/4 \left \| \sum_{i}^{}\lambda _{i}y _{i } x _{i}\right \|}\)</span>, then we get the following</p>
<p><img src="https://i.loli.net/2019/11/20/8CZfKqxytmOoYih.png"></p>
<p>interpreting results</p>
<p><img src="https://i.loli.net/2019/11/20/WUvX9rTzie2xRn4.png"></p></li>
</ul>
<h3 id="soft-c-svm">1.5.4. soft C-SVM</h3>
<ul>
<li><p><strong>Def</strong>: soft SVM</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kd7xe38j30sc024jrf.jpg"></p>
<ul>
<li><p><strong>Qua</strong>: basic transform</p>
<p>trans: change |x&lt;1| to (1-x)+ , basiclly is the same .</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kdj455cj30ok02q3ym.jpg"></p>
<p>trans: slack variable</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kdp69btj30rs046aac.jpg"></p>
<p>lagranrian function =&gt; dual lagranian function</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kemgiihj30rk08gdgt.jpg"></p>
<p>dual problem</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kev03x5j30pg036t8v.jpg"></p>
<p>complementary slackness conditions : This implies that all the support vectors with y = 1 lie in the half-plane {x : xT w ≤ 1}.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kfc3xu7j30ni03oq35.jpg"></p>
<p>insights from above:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94l67o489j314q088wgp.jpg"></p>
<p>choose c</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94l6l7zfcj316e0380tf.jpg"></p></li>
</ul></li>
<li><p><strong>Qua</strong>: interpreting in another way( loss function + regularization)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94llq6xidj315w03ct92.jpg"></p></li>
</ul>
<h3 id="soft--svm">1.5.5. soft $ $-SVM</h3>
<ul>
<li><p><strong>Def</strong>: a more interpretable way, since <span class="math inline">\(\nu\)</span> is more easy to set.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lf89bzoj314a05gwey.jpg"></p>
<ul>
<li><p><strong>Qua</strong>: basic transition</p>
<p>slack variables</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lfwvlcxj315607y0tg.jpg"></p>
<p>lagrange dual function</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lgbmkh1j30wi03oglu.jpg"></p>
<p>dual problem</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lgoido3j30y208oq3v.jpg"></p>
<p>insights for slackness</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lhpmmmmj316804wt9z.jpg"></p></li>
<li><p><strong>Qua</strong>: interpretation of <span class="math inline">\(\nu\)</span> : we can interpret <span class="math inline">\(nu\)</span> as being approximately the fraction of data that are margin errors.</p>
<p>[](/Users/huangbenson/Library/Application Support/typora-stats_theory(https://tva1.sinaimg.cn/large/006y8mN6ly1g94litz5uxj316604g3zx.jpg)</p></li>
<li><p><strong>Qua</strong>: <span class="math inline">\(\nu\)</span> and C SVM are the same</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94ljbz53fj316o02gt99.jpg"></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94ljika20j317a0lon06.jpg"></p></li>
</ul></li>
</ul>
<h3 id="sensitive-svm-1-10">1.5.6. $ $-sensitive SVM (1-10)</h3>
<ul>
<li><p><strong>Def</strong>: a relaxation of loss function</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jkwn25kj31d60hajuf.jpg"></p></li>
</ul>
<h1 id="bayes-algorithm">2. bayes algorithm</h1>
<h2 id="bayes-algorithm-1">2.1. bayes algorithm</h2>
<ul>
<li><p><strong>Def</strong>:</p></li>
<li><p><strong>Def</strong>: using kernel to interpretate</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jk8garjj31ca0ma79u.jpg"></p></li>
</ul>
<h1 id="regression-algorithm">3. regression algorithm</h1>
<h2 id="kernel-ridge-regression-1-10">3.1. kernel ridge regression (1-10)</h2>
<ul>
<li><p><strong>Def</strong>: kernel regression</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jg6n3h0j31c20fgtbh.jpg"></p>
<p><strong>Note</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jgg2rpcj317g0eutal.jpg"></p></li>
</ul>
<h2 id="logistic-regression-1-13">3.2. logistic regression (1-13)</h2>
<ul>
<li><p><strong>Def</strong>: logistic regression</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95mj6tnn0j318o0640w1.jpg"></p>
<p><strong>Algorithm</strong>: maximum likelihood</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95mjwxpazj315y0dc0v5.jpg"></p></li>
</ul>
<h1 id="ensemble-algorithm">4. ensemble algorithm</h1>
<ul>
<li><p><strong>Def</strong>: ensemble methods</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jox8hk9j311i0u042p.jpg"></p></li>
</ul>
<h2 id="adaboost-1-12-1-13">4.1. adaboost (1-12, 1-13)</h2>
<ul>
<li><p><strong>Def</strong>: adaboost</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jqrjkmjj315m084dh1.jpg"></p>
<p><strong>Algorithm</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jrlyyqij317c0a8q5c.jpg"></p>
<ul>
<li><p><strong>Theorem</strong>: upper bound for Em-Ft-loss of adaboost</p>
<p><strong>Usage</strong>: ensuring the performace.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jrxmf2cj314i092wfg.jpg"></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95kzuorryj313c0mwtbm.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95l02cd6kj31340mkdic.jpg"></p></li>
<li><p><strong>Theorem</strong>: for standardized F</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95js9pkqkj316k08cq4q.jpg"></p></li>
<li><p><strong>Theorem</strong>: there exist upper bound for loss function, if conditions are met.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95l4x2rifj316a05ugml.jpg"></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95l513c30j315i0f0q57.jpg"></p></li>
<li><p><strong>Theorem</strong>: use gradient decent to explain adaboost</p>
<p><strong>Usage</strong>: iteratively solving adaboost is equivalent to minimizing the true loss function of <span class="math inline">\(e ^{-YF _{T}(x)}\)</span></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jsuxibxj316205wgml.jpg"></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95lgbda3bj319u0h6dj1.jpg"></p>
<p><strong>Note</strong>: loss function: For every t from 1 to T, we can expand the E(exp(-YX)) thing, and we can see that adaboost is minimizing Eexp(YFT(X)) at every step, thus the we are using step-wise gradient decent to optimize the Eexp(-YX).</p>
<p>The whole picture: So this is the idea of adaboost, we choose fT to minimize eT as a step-wise gradient descent, then we find out we can see adaboost as E(-YX) in whole, so we choose <span class="math inline">\(\alpha T\)</span> to make that happen.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95ldb2stkj31ac05g40g.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95m3zu4mkj316c054mxx.jpg"></p></li>
<li><p><strong>Qua</strong>: similarity to logistic regression (1-13)</p>
<p>using taylor expansion we can see that the first elements are the same ( <span class="math inline">\(ln(1+e ^{-2a})+1-ln2\)</span> &amp; <span class="math inline">\(e(-a)\)</span>)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95mln63k6j316407o3zu.jpg"></p>
<p>e(-a) is above</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95n9q6myzj30oc0dy0tu.jpg"></p>
<p>differences: 1) e(-a) are larger 2) adaboost is approximation of max-likelihood logistic regression with larger penalty.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95nakqg24j316i09cdi1.jpg"></p></li>
</ul></li>
<li><p><strong>Qua</strong>: PAC related</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95o80ulhcj315g0f643c.jpg"></p></li>
<li><p><strong>Def</strong>: generalized adaboost:</p>
<p><strong>Usage</strong>: in adaboost, we use exp(-YX) as loss, here we can have different options and still implement the step-wise adaboost core idea: we see J(F) as the loss, F is the variable, and each step we take <span class="math inline">\(F+\alpha _{t}f _{t}\)</span></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jtgz619j31880kmad7.jpg"></p>
<p>recall: (convex optimization)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95luzezzcj31b00d0dml.jpg"></p>
<p><strong>Algorithm</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jtonm5mj316u0by0vb.jpg"></p></li>
</ul>

      
    </div>
    
    
    

    <div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>Title:</span><a href="/2019/11/19/stats_theory/">Statistical Learning Theory</a></p>
  <p><span>Author:</span><a href="/" title=" Benson 的personal blog">Benson</a></p>
  <p><span>PTime:</span>2019/11/19 - 12:11</p>
  <p><span>LUpdate:</span>2019/11/29 - 15:11</p>
  <p><span>Link:</span><a href="/2019/11/19/stats_theory/" title="Statistical Learning Theory">https://steinsgate9.github.io/2019/11/19/stats_theory/</a>
    <span class="copy-path"  title="click to copy link"><i class="fa fa-clipboard" data-clipboard-text="https://steinsgate9.github.io/2019/11/19/stats_theory/"  aria-label="copy done！"></i></span>
  </p>
  <p><span>Protocal:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)</a> Please keep the original link and author.</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: 'copy done',
          icon: "success", 
          showConfirmButton: true
          });
    });
    });  
</script>

      
    </div>
    
    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="Benson WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.png" alt="Benson Alipay"/>
        <p>Alipay</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/numerical-stats/" rel="tag"># numerical stats</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/11/19/multivariate-statical-analysis/" rel="prev" title="Multivariate Statical Analysis">
                Multivariate Statical Analysis <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- Go to www.addthis.com/dashboard to customize your tools -->
<div class="addthis_inline_share_toolbox">
  <script type = "text/javascript" src = "//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5dd409321289b452" async = "async" ></script>
</div>

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80NzYxNi8yNDExNA"></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://tva1.sinaimg.cn/large/006y8mN6gy1g96p07mbexj30uf0u0npd.jpg"
                alt="Benson" />
            
              <p class="site-author-name" itemprop="name">Benson</p>
              <p class="site-description motion-element" itemprop="description">Benson's personal blog, including stats, cs, math, among others.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/SteinsGate9" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="bensonuouououow@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-globe"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://twitter.com/bensonuouououo" target="_blank" title="Twitter">
                      
                        <i class="fa fa-fw fa-globe"></i>Twitter</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.instagram.com/bensonuouououo/" target="_blank" title="Instagram">
                      
                        <i class="fa fa-fw fa-globe"></i>Instagram</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.alloyteam.com/nav/" title="Web前端导航" target="_blank">Web前端导航</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.chuangzaoshi.com/code" title="创造狮导航" target="_blank">创造狮导航</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.36zhen.com/t?id=3448" title="前端书籍资料" target="_blank">前端书籍资料</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://e.xitu.io/" title="掘金酱" target="_blank">掘金酱</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.v2ex.com/" title="V2EX" target="_blank">V2EX</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.v2ex.com/" title="印记中文" target="_blank">印记中文</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#generalized-expected-risk"><span class="nav-text">1. generalized expected risk</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#learning-algorithm-loss-functions-1-1-3-1"><span class="nav-text">1.1. learning algorithm &amp; loss functions (1-1, 3-1)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#loss-functions"><span class="nav-text">1.2. loss functions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#e-f-loss-1-1-3-1"><span class="nav-text">1.2.1. E-f-loss (1-1, 3-1)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#e-f_hateta-loss-plug-in-classifiers-1-1-3-2"><span class="nav-text">1.2.2. E-\(f_\hat{\eta}\)-loss (plug-in classifiers) (1-1, 3-2)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#e-f-newloss-1-6-1-7"><span class="nav-text">1.2.3. E-f-newloss (1-6, 1-7)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#em-f-loss-1-213-3-345"><span class="nav-text">1.2.4. Em-f-loss (1-2,13, 3-3,4,5)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#em-f-loss"><span class="nav-text">1.2.4.1. Em-f-loss</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#uniform-deviation-bound"><span class="nav-text">1.2.4.1.1. uniform deviation bound</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#vc-bound"><span class="nav-text">1.2.4.1.2. vc bound</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#bound-improvement-by-approximation-error"><span class="nav-text">1.2.4.1.3. bound improvement by approximation error</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#uap-approximate-error"><span class="nav-text">1.2.4.1.3.1. UAP &amp; approximate error</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#sieve-estimators"><span class="nav-text">1.2.4.1.3.2. sieve estimators</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#rate-of-convergence"><span class="nav-text">1.2.4.1.3.3. rate of convergence</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#empirical-processing-theory"><span class="nav-text">1.2.4.2. empirical processing theory</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#glivenko-cantelli"><span class="nav-text">1.2.4.2.1. Glivenko-Cantelli</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#empirical-distribution-function-book-2-2"><span class="nav-text">1.2.4.2.1.1. empirical distribution function (book, 2-2)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#gc-class-theory-1-16-2-2"><span class="nav-text">1.2.4.2.1.2. GC class &amp; theory (1-16, 2-2)</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#symmetrization-lemma-2-5"><span class="nav-text">1.2.4.2.2. symmetrization lemma (2-5)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#uniform-convergence-uniform-law-of-large-numbers-1-1314-2-6"><span class="nav-text">1.2.4.2.3. uniform convergence &amp; uniform law of large numbers (1-13,14, 2-6)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#vc-class-and-stuff"><span class="nav-text">1.2.4.2.4. vc class and stuff</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#covering-number-2-7-2-8"><span class="nav-text">1.2.4.2.4.1. covering number (2-7, 2-8)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#entropy"><span class="nav-text">1.2.4.2.4.2. entropy</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#vc-theory-for-sets3-5"><span class="nav-text">1.2.4.2.4.3. vc theory for sets(3-5)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#mono-layer-a-special-classifier3-5"><span class="nav-text">1.2.4.2.4.4. mono layer (a special classifier)(3-5)</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#p-glivenko-cantelli-for-class-f"><span class="nav-text">1.2.4.2.5. P-Glivenko-Cantelli (for class F)</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#alternative-goals"><span class="nav-text">1.3. alternative goals</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#maximum-likelihood"><span class="nav-text">1.3.1. maximum likelihood</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#probably-approximately-correct-1-13-3-4"><span class="nav-text">1.3.2. probably approximately correct (1-13, 3-4)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#perceptron-algorithim"><span class="nav-text">1.4. perceptron algorithim</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#support-vector-machine"><span class="nav-text">1.5. support vector machine</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#basic-svm"><span class="nav-text">1.5.1. basic SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kernel-svm"><span class="nav-text">1.5.2. kernel SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#primal-svm"><span class="nav-text">1.5.3. primal SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#soft-c-svm"><span class="nav-text">1.5.4. soft C-SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#soft--svm"><span class="nav-text">1.5.5. soft $ $-SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sensitive-svm-1-10"><span class="nav-text">1.5.6. $ $-sensitive SVM (1-10)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#bayes-algorithm"><span class="nav-text">2. bayes algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#bayes-algorithm-1"><span class="nav-text">2.1. bayes algorithm</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#regression-algorithm"><span class="nav-text">3. regression algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#kernel-ridge-regression-1-10"><span class="nav-text">3.1. kernel ridge regression (1-10)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#logistic-regression-1-13"><span class="nav-text">3.2. logistic regression (1-13)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ensemble-algorithm"><span class="nav-text">4. ensemble algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#adaboost-1-12-1-13"><span class="nav-text">4.1. adaboost (1-12, 1-13)</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2015 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Benson</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      total visitors
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      people
    </span>
  

  
    <span class="site-pv">
      total read
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      times
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.4"></script>



  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.staticfile.org/MathJax/MathJax-2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
