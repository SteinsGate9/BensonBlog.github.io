<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.jpg?v=5.1.4">


  <link rel="mask-icon" href="/images/favicon.ico?v=5.1.4" color="#222">





  <meta name="keywords" content="stats," />










<meta name="description" content="ESL + PRPL + stats learning theory notes">
<meta name="keywords" content="stats">
<meta property="og:type" content="article">
<meta property="og:title" content="Statistical Learning Theory">
<meta property="og:url" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;2019&#x2F;11&#x2F;19&#x2F;stats_theory&#x2F;index.html">
<meta property="og:site_name" content="BeNsoN">
<meta property="og:description" content="ESL + PRPL + stats learning theory notes">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;VqdvoazPSMInTQ2.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;OyqKboHkSQNDn75.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;HMS9BAGx8XZPTyQ.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;WEKaf4uoeIAlkc7.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jeljh2lj31c808wjt3.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jecq5rdj31cs0iuwgd.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;x7kQeKi8ybTrHwd.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;QrMq8YUoezv5lfF.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;nkh94C5FBHaPKdV.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;qYFxsHPloQND5w7.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;29vwoHBuIPEygGZ.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;3hfPieqtNvQcYol.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;31ckzfgGZ5vUaQm.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;QPOR4bGDZgHcIwM.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;WQcTBePXsGjtoEV.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lqs6o72j30p602kwem.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lrsn8ebj315g03iwes.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94o1xyvb9j30qq08g3zb.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94nwmwcxkj30rg04m3z2.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94o4i1hlkj30r001u0t2.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94nxbw79oj30ri02et8v.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qbhcivdj31570u07bt.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qc9fbg5j315u046aaj.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94qc3sof4j316q046mya.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95oi2w8gtj316804w0w9.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95oj97tgqj316008kq5h.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95ojr0phij315a0kggnt.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95ojwr4yzj315w04a0tq.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95ww91lpyj318u0p4ni8.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wwhbs4yj30o104iglz.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wxp8pjbj30pe0340u7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wxx4mb1j317o0bm49j.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wy58truj30zs0k816h.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95wx02eexj30o5012t8l.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95r5on66nj316k04gwf6.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95r5wpu0mj317009275x.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95x6ig9taj30nu03tq38.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962lasmw3j319007y7bn.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962licechj318e05ogsc.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962lpaos0j31820c4jwn.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962veanruj30oo02at91.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962mdqdqvj318o07ygoz.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962mom5nrj30nw0fgt9n.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962nvb719j30oa01v3yj.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962npactvj3192096aeh.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g962o65ukwj30ox098gm9.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95pm0mzxxj31760iqaeu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95px5f6gjj317m0jgwip.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g96450i51uj30o305pab5.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964l986unj30ot0dm75n.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964li6gk5j30ny031aai.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964nsneufj30og02lt8y.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964pd0whnj30nv04ljrp.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964vbn2zuj30o40210su.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964vlz3hcj30og02gglt.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964pko8wij30ll03bjrf.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964r6bma5j30mv08w74u.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964rewnt9j30o307a3yw.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964rjujfgj30o703a74c.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964sdwcymj30o3060dg7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964ys8qbkj30od02zgm9.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964whyhyoj30n801j747.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964yzm3znj30og02fdg3.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964z6ewrbj30nh018aa2.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964zbzzkoj30oe047aaz.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g964ziid51j30nx05daal.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;steinsgate9.github.io&#x2F;Users&#x2F;huangbenson&#x2F;Library&#x2F;Application%20Support&#x2F;typora-user-images&#x2F;image-20191015161855035.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g96ml75k6hj30nl02gmx7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95npharqmj30ck04874b.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95o9tuhy7j315m07awg7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95o9zv0drj315y0560tu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95oaciywjj316y072wfk.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95nkp8b07j31660ekwhc.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95nlmbv8fj316k092jsx.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95o8uz3txj315u06qgna.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95olftvxlj316s0dqacl.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;eJ6NBMAcbIR9mFO.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94uosvr98j30us09gt9p.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94uoljm4lj30v00emta4.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;Qpn3gXHzTPF2aZY.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94uo4jzd8j30uk030aak.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;tgpQOvDowBsfxHN.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;q68lQbYzNG9xjSs.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;NcJWjmECne4zbg1.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;5goRmWdDwpyv8hK.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;MtqP29VGAsvCU6B.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;VqbT2vfYJE9oSH3.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;zdSptJbWMUu9DQm.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;OzXTrZA4jmY9hVx.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94un7bhjsj30wc0byta5.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;HR7Fxa9ZECuMVeS.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;h8gfUSourM4qYQw.png">
<meta property="og:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;20&#x2F;MWp8JJ.png">
<meta property="og:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;20&#x2F;MWpAiQ.png">
<meta property="og:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;20&#x2F;MWpfw8.png">
<meta property="og:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;20&#x2F;MWpOmV.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;pzyisx7Ag5mFQGv.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;qVtT6Qz1an5b3mK.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94ume9k1hj30ts024a9y.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94ullkwx7j30w209qq4b.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;UbqFniyShgl627Y.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;Jg5KwYC4clsp1LO.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;SwgJqitobc2Xvku.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;IrRWNKDMTS9mn6l.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;Jg5KwYC4clsp1LO.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;WFjVfnO7pPeCmqd.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;H13oW6M2znwQlKY.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;ksrwUoluGiF7jMI.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;eJiRtwo5M9AEkDN.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;oYLf9tT3VOjEwUW.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;IyrRtMfzo4mJelU.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;Wbrua1oidJILVPp.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;8CZfKqxytmOoYih.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;WUvX9rTzie2xRn4.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kd7xe38j30sc024jrf.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kdj455cj30ok02q3ym.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kdp69btj30rs046aac.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kemgiihj30rk08gdgt.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kev03x5j30pg036t8v.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94kfc3xu7j30ni03oq35.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94l67o489j314q088wgp.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94l6l7zfcj316e0380tf.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94llq6xidj315w03ct92.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lf89bzoj314a05gwey.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lfwvlcxj315607y0tg.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lgbmkh1j30wi03oglu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lgoido3j30y208oq3v.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94lhpmmmmj316804wt9z.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94litz5uxj316604g3zx.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94ljbz53fj316o02gt99.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g94ljika20j317a0lon06.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jkwn25kj31d60hajuf.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jk8garjj31ca0ma79u.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jg6n3h0j31c20fgtbh.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jgg2rpcj317g0eutal.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95mj6tnn0j318o0640w1.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95mjwxpazj315y0dc0v5.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jox8hk9j311i0u042p.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jqrjkmjj315m084dh1.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jrlyyqij317c0a8q5c.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jrxmf2cj314i092wfg.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95kzuorryj313c0mwtbm.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95l02cd6kj31340mkdic.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95js9pkqkj316k08cq4q.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95l4x2rifj316a05ugml.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95l513c30j315i0f0q57.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jsuxibxj316205wgml.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95lgbda3bj319u0h6dj1.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95ldb2stkj31ac05g40g.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95m3zu4mkj316c054mxx.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95mln63k6j316407o3zu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95n9q6myzj30oc0dy0tu.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95nakqg24j316i09cdi1.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95o80ulhcj315g0f643c.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jtgz619j31880kmad7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6ly1g95luzezzcj31b00d0dml.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006y8mN6gy1g95jtonm5mj316u0by0vb.jpg">
<meta property="og:updated_time" content="2019-11-22T02:51:37.008Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;11&#x2F;20&#x2F;VqdvoazPSMInTQ2.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: 'FV65T83Q2V',
      apiKey: '5008cf0478de4ac53102baceee722a4d',
      indexName: 'steinsgate9',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://SteinsGate9.github.io/2019/11/19/stats_theory/"/>





  <title>Statistical Learning Theory | BeNsoN</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/SteinsGate9" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">BeNsoN</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Live Long, Play Hard.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            About
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" target="_blank" rel="noopener" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://SteinsGate9.github.io/2019/11/19/stats_theory/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Benson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g96p07mbexj30uf0u0npd.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BeNsoN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Statistical Learning Theory</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-19T12:50:43+08:00">
                2019-11-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/statistics/" itemprop="url" rel="index">
                    <span itemprop="name">statistics</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv">total read
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>times
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  3.9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  23
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>ESL + PRPL + stats learning theory notes</p>
<a id="more"></a>

<h1 id="generalized-expected-risk">1. generalized expected risk</h1><h2 id="learning-algorithm-amp-loss-functions-1-1-3-1">1.1. learning algorithm &amp; loss functions (1-1, 3-1)</h2><ul>
<li><p><strong>Def</strong>: learning algorithm (3-1)</p>
<p><img src="https://i.loli.net/2019/11/20/VqdvoazPSMInTQ2.png" alt="image.png"></p>
<ul>
<li><p><strong>Def</strong>: weakly consistent / strongly consistent</p>
<p><img src="https://i.loli.net/2019/11/20/OyqKboHkSQNDn75.png" alt="image.png"></p>
<p><strong>Note</strong>: </p>
<p><img src="https://i.loli.net/2019/11/20/HMS9BAGx8XZPTyQ.png" alt="image.png"></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: loss (loss function) (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/WEKaf4uoeIAlkc7.png" alt="image.png"></p>
<p><strong>Note</strong>: the relation of max likelihood &amp; loss function (1-10)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jeljh2lj31c808wjt3.jpg" alt></p>
<p> <strong>Example</strong>: (1-10)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jecq5rdj31cs0iuwgd.jpg" alt></p>
</li>
</ul>
<h2 id="loss-functions">1.2. loss functions</h2><h3 id="E-f-loss-1-1-1-2-1-3-1-7-3-2">1.2.1. E-f-loss (1-1, 1-2,  1-3, 1-7, 3-2)</h3><h4 id="E-f-loss">1.2.1.1. E-f-loss</h4><ul>
<li><p><strong>Def</strong>: E-f-loss  (generalized expected risk) (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/x7kQeKi8ybTrHwd.png" alt="image.png"></p>
</li>
<li><p><strong>Def</strong>: min-E-f-loss (minimal generalized expected risk) (1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/QrMq8YUoezv5lfF.png" alt="image.png"></p>
<ul>
<li><p><strong>Theorm</strong>: min-E-f-loss for binary classification </p>
<p>(1-1)</p>
<p><img src="https://i.loli.net/2019/11/20/nkh94C5FBHaPKdV.png" alt="image.png"></p>
<p>(3-2)</p>
<p>![image-20191031153103125](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031153103125.png)</p>
<p>![image-20191031153115435](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031153115435.png)</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>: (3-1) =&gt; L*</p>
<p>![image-20191031153216877](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031153216877.png)</p>
<p>note:</p>
<p>![image-20191031153335442](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031153335442.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>: E-f-loss - min-E-f-loss (1-2, 3-1) </p>
<p><strong>Usage</strong>: find f to estimate f* </p>
<p>3-2</p>
<p>![image-20191031153249270](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031153249270.png)</p>
<p><strong>Note</strong>:</p>
<p>![image-20191031153310730](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031153310730.png)</p>
<p>1-1</p>
<p><img src="https://i.loli.net/2019/11/20/qYFxsHPloQND5w7.png" alt="image.png"></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://i.loli.net/2019/11/20/29vwoHBuIPEygGZ.png" alt="image.png"></p>
<p><strong>Note</strong>: we can see that $\eta$ is what we what to estimate, the goal turns to find a better $\eta$.</p>
<p><img src="https://i.loli.net/2019/11/20/3hfPieqtNvQcYol.png" alt="image.png"></p>
<ul>
<li><p><strong>Corollary</strong>: E-$f_\hat{\eta}$-loss - min-E-f-loss​</p>
<p><strong>Usage</strong>: when using $\hat{\eta}$ to find $f^<em>$, instead of directly finding $f^</em>$, what’s the bound?</p>
<p><img src="https://i.loli.net/2019/11/20/31ckzfgGZ5vUaQm.png" alt="image.png"></p>
<p><strong>Proof</strong>: </p>
<p><img src="https://i.loli.net/2019/11/20/QPOR4bGDZgHcIwM.png" alt="image.png"></p>
<p><strong>Note</strong>: figure / pros &amp; cons to use $\hat{\eta}$ to minimize E loss </p>
<p><img src="https://i.loli.net/2019/11/20/WQcTBePXsGjtoEV.png" alt=" "></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>: f_u-loss - f*-loss (3-1)</p>
<p>![image-20191031150358387](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031150358387.png)</p>
<p>note:</p>
<p>![image-20191031150408817](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031150408817.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>:  E(f-loss)</p>
<p><strong>Note</strong>:</p>
<p>![image-20191031152449245](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031152449245.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Corollary</strong>: for perceptron specific</p>
<p>![image-20191031152618174](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031152618174.png)</p>
</li>
<li><p><strong>Corollary</strong>: stricter condition, better bound </p>
<p>![image-20191031152654991](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031152654991.png)</p>
</li>
</ul>
<h3 id="E-f-newloss-1-6-1-7">1.2.2. E-f-newloss (1-6, 1-7)</h3><ul>
<li><p><strong>Def</strong>: E-f-newloss</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lqs6o72j30p602kwem.jpg" alt></p>
<p><strong>Note</strong>: SVM </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lrsn8ebj315g03iwes.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>:  =&gt; elaboration</p>
<p><strong>Usage</strong>: we can minimize E-f-newloss by minimizing the follows at every x/</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94o1xyvb9j30qq08g3zb.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: new elements to compute min-E-f-newloss, $H(\eta)$ means the lowest point of all f, all x.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94nwmwcxkj30rg04m3z2.jpg" alt></p>
<p><strong>Note</strong>: SVM</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94o4i1hlkj30r001u0t2.jpg" alt></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94nxbw79oj30ri02et8v.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: when $\phi$ is convex =&gt; $H ^{-}(\eta)$ = $\phi(0)$ </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qbhcivdj31570u07bt.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: classification - calibrated </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qc9fbg5j315u046aaj.jpg" alt></p>
<p><strong>Example</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94qc3sof4j316q046mya.jpg" alt></p>
</li>
</ul>
<pre><code>- **Qua**:  necc &amp; suff 

  ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g94qcjj6jij315006aaaq.jpg)

  **Proof**: too long



- **Qua**:  real gap is bounded by E-f-newcalibratedloss

  ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g94qmpvb92j311e0bkmyh.jpg)

  **Proof**: too long 

  **Example**: in the case of SVM, $\phi$ is a given convex function, therefore we can conpute $H(\phi)$ and yield a upper bound for the real gap. which means when training performs good, the result will most likely be the same. 

  ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g94qpmgeaij317a0aajsy.jpg)

  **Example**: adaboost is the same, $\phi(a)$ is convex and we can again use theorem 2.2

  ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g94qpy0kq6j315k07wabg.jpg)

  **Example**: adaboost(1-13), a more detailed explaination, $\phi$ is class-calibrated, so we can use theorem 2.2.

  ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g95ma9grqbj315c0bgwgb.jpg)

  ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g95maf8kpaj319a0f0wh3.jpg)</code></pre><h3 id="Em-f-loss-1-13-3-3">1.2.3. Em-f-loss (1-13, 3-3)</h3><h4 id="Em-f-loss-1-2-1-13-3-3">1.2.3.1. Em-f-loss (1-2, 1-13, 3-3)</h4><ul>
<li><p><strong>Def</strong>:  f-emloss (f changed &amp; loss changed)</p>
<p>1-2</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95oi2w8gtj316804w0w9.jpg" alt></p>
<p>3-3</p>
<p>![image-20191015164540607](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015164540607.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: Em-f-loss converge to E-f-loss (1-13)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95oj97tgqj316008kq5h.jpg" alt></p>
<p><strong>Proof</strong>: why E(empirical risk) = generalized : E(h) is actually P(y|x), so $E(\hat{E}(h))=\sum_n E(1(…))/n=\sum_n p/n = p $ </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95ojr0phij315a0kggnt.jpg" alt> </p>
<p><strong>Note</strong>: </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95ojwr4yzj315w04a0tq.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: =&gt;  E( f-emloss)(3-3)</p>
<p>![image-20191031223954634](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031223954634.png)</p>
</li>
<li><p><strong>Theorm</strong>:: =&gt; hoeffding bound (3-3) (know h)</p>
<p>![image-20191031224401007](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031224401007.png)</p>
<ul>
<li><p>apply: (3-3) </p>
<p>usage: can be used to analysize the empical risk</p>
<p>![    ](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031224603996.png)</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>:: =&gt; case 1 uniform deviation bound (bound the performance of em)(3-4)(not know h)</p>
<p>![image-20191023001520129](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023001520129.png)</p>
<p>proof:</p>
<p>![image-20191023001529332](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023001529332.png)</p>
<p>note:</p>
<p>![image-20191031224151711](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031224151711.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>: =&gt; case 2 unifrom devia bound (3-5)</p>
<p>![image-20191031230141704](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031230141704.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: min emperical risk (h=f=lossfunction) (3-4)</p>
<p>![image-20191031154320453](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031154320453.png)</p>
<p>![image-20191031154326665](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031154326665.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: =&gt; em bound (3-4)</p>
<p>![image-20191023001620424](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023001620424.png)</p>
<p>note:</p>
<p>![image-20191023001701362](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023001701362.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>: =&gt; bound2 (3-4)</p>
<p>![image-20191023001751101](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023001751101.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>:: =&gt; vc bound 3 (3-5)</p>
<p>![image-20191031230223298](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031230223298.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>: =&gt; learnable (3-5)</p>
<p>![image-20191031230308646](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031230308646.png)</p>
</li>
</ul>
<h4 id="empirical-processing-theory">1.2.3.2. empirical processing theory</h4><p><strong>Goal</strong>: to make Em &amp; E close enought</p>
<p>Empirical Process theory allows us to prove uniform convergence laws of various kinds. One of the ways to start Empirical Process theory is from the Glivenko-Cantelli theorem.  This leads to the question of whether the same idea can be generalized to other function classes. </p>
<h5 id="empirical-distribution-function">1.2.3.2.1. empirical distribution function</h5><ul>
<li><p><strong>Def</strong>: empirical distribution function  </p>
<p>(book)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95ww91lpyj318u0p4ni8.jpg" alt></p>
<p>(2-2)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wwhbs4yj30o104iglz.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: =&gt; is a statistic </p>
</li>
<li><p><strong>Qua</strong>: =&gt; range </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wxp8pjbj30pe0340u7.jpg" alt></p>
</li>
<li><p><strong>Qua</strong>: =&gt; other interpretation</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wxx4mb1j317o0bm49j.jpg" alt></p>
</li>
<li><p><strong>Qua</strong>: =&gt; limits</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wy58truj30zs0k816h.jpg" alt></p>
<p>(2-2)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95wx02eexj30o5012t8l.jpg" alt></p>
</li>
</ul>
<h5 id="Glivenko-Cantelli-theory-1-16">1.2.3.2.2. Glivenko-Cantelli theory (1-16)</h5><ul>
<li><p><strong>Def</strong>: GC class (1-16)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95r5on66nj316k04gwf6.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Theorem</strong>: GC theory </p>
<p>(1-16)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95r5wpu0mj317009275x.jpg" alt="    "></p>
<p>(2-2)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95x6ig9taj30nu03tq38.jpg" alt></p>
<p>(book)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962lasmw3j319007y7bn.jpg" alt></p>
<p><strong>Note</strong>: Fn and F is very close when n is large </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962licechj318e05ogsc.jpg" alt></p>
</li>
</ul>
<h5 id="symmetrization-2-5">1.2.3.2.3. symmetrization (2-5)</h5><p>EPT allows us to prove convergence.</p>
<ul>
<li><p><strong>Def</strong> : recall distribution function  (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962lpaos0j31820c4jwn.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: Rademacher variables  (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962veanruj30oo02at91.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Lemma</strong>: first symmtry =&gt; bound the Fn-F(t)  (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962mdqdqvj318o07ygoz.jpg" alt></p>
<p><strong>Example</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962mom5nrj30nw0fgt9n.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Lemma</strong>: second symmtry =&gt; aallowsustoreplacethedifferenceFn−Fn′ withasingleempiricalquantity consisting of n observations. We can further bound the latter so that the bound is independent of the data ξ. (2-5)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962nvb719j30oa01v3yj.jpg" alt></p>
<p><strong>Note</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962npactvj3192096aeh.jpg" alt></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g962o65ukwj30ox098gm9.jpg" alt></p>
</li>
</ul>
<h5 id="uniform-convergence-amp-uniform-law-of-large-numbers">1.2.3.2.4. uniform convergence &amp; uniform law of large numbers</h5><p><strong>Goal</strong>: for every F, make Em &amp; E close enough. we can first generalize the Glivenko-Cantelli theorem (a special F space).</p>
<ul>
<li><p><strong>Intro</strong>: what is and why we should use uniform convergence:  (1-13, 1-14)</p>
<p>if there’s only one function in F, we simply use law of large numbers, then we can prove convergence, but it is of no use.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95pm0mzxxj31760iqaeu.jpg" alt></p>
<p><strong>Example</strong>: when F contains more functions and here the case is when dataset are separated, empirical risk are sometimes not convergence to real risk.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95px5f6gjj317m0jgwip.jpg" alt></p>
<p><strong>Example</strong>: the GC theorem in function way (2-6)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g96450i51uj30o305pab5.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: uniform law of large numbers (2-6)</p>
<p><strong>Usage</strong>: when we F specialize to indicators</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964l986unj30ot0dm75n.jpg" alt></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964li6gk5j30ny031aai.jpg" alt></p>
</li>
</ul>
<p>​    </p>
<h5 id="vc-class-and-stuff">1.2.3.2.5. vc class and stuff</h5><p>######vc class (2-7, 3-5)</p>
<ul>
<li><p><strong>Def</strong>: vc class (2-6)</p>
<p><strong>Usage</strong>: vc class , C是很多range的集合，X是大range，Vc的意思是：取x中的n个点，如果C中的range不能把n个点分成2的n次方份的话，那么C的Vc位数就是n。如果分成功，那么就说shatter。</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964nsneufj30og02lt8y.jpg" alt></p>
<p><strong>Example</strong>:(2-6)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964pd0whnj30nv04ljrp.jpg" alt></p>
<p><strong>Example</strong>: half space(2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964vbn2zuj30o40210su.jpg" alt></p>
<p><strong>Example</strong>: subgraph (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964vlz3hcj30og02gglt.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Lemma</strong>:  =&gt; the relation ship between m(n) and Vc (2-6) </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964pko8wij30ll03bjrf.jpg" alt></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964r6bma5j30mv08w74u.jpg" alt></p>
<p><strong>Note</strong>: that we can use VC to see Pn (2-6)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964rewnt9j30o307a3yw.jpg" alt></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964rjujfgj30o703a74c.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: operation (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964sdwcymj30o3060dg7.jpg" alt></p>
</li>
</ul>
<p>​    </p>
<h6 id="covering-number">1.2.3.2.5.1. covering number</h6><ul>
<li><p><strong>Def</strong>: covering number (a more powerful way than VC) (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964ys8qbkj30od02zgm9.jpg" alt></p>
<p><strong>Note</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964whyhyoj30n801j747.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: metric entropy  (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964yzm3znj30og02fdg3.jpg" alt></p>
<ul>
<li><p><strong>Def</strong>: totally bounded (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964z6ewrbj30nh018aa2.jpg" alt></p>
</li>
</ul>
</li>
<li><p><strong>Def</strong>: entropy with bracking (2-7)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964zbzzkoj30oe047aaz.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: relation of metric &amp; brackeing entropy </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g964ziid51j30nx05daal.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><em>*Def</em></p>
<p>3-5 </p>
<p>![image-20191023084954302](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023084954302.png)</p>
<p>![image-20191031155148245](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031155148245.png)</p>
<p>![image-20191031155102472](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031155102472.png)</p>
<p>examples:<br>![image-20191015161410728](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015161410728.png)</p>
<p>example:</p>
<p>![image-20191031214247615](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031214247615.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>:: =&gt; bound of VC for broad family of classes (3-5)</p>
<p>![image-20191023090336899](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023090336899.png)</p>
<p>example:</p>
<p>![image-20191023090423390](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023090423390.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>::Sauer =&gt; bound of shatter coefficient m(n) (3-5)</p>
<p>3-5 </p>
<p>![image-20191031155506860](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031155506860.png)</p>
<p>2-7 </p>
<p>![image-20191015155449987](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015155449987.png)</p>
<p>proof:</p>
<p>![image-20191015155457506](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015155457506.png)</p>
<p>example:</p>
<p>![image-20191023090821715](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023090821715.png)</p>
</li>
</ul>
<pre><code>- **Corollary**: =&gt; another bound of shatter coefficient m(n) (3-5)

  ![image-20191023090621955](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023090621955.png)

- **Corollary**: =&gt; another bound of shatter coefficient m(n) (3-5)

  ![image-20191023090658296](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023090658296.png)

- **Corollary**: =&gt; same  (3-5)

  ![image-20191023090735662](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023090735662.png)



- Qua:  =&gt; more bound (2-7)

  ![image-20191015155505329](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015155505329.png)

  ![image-20191015155551424](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015155551424.png)</code></pre><h5 id="vc-theory-for-sets-3-5">1.2.3.2.6. vc theory for sets(3-5)</h5><ul>
<li><p><strong>Theorm</strong>: VC theory =&gt; convergence guarantees for an empirical risk minimizing classifier when the VC dimen- sion of the classifier set H was finite. (3-5)</p>
<p>![image-20191023091054642](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023091054642.png)</p>
<ul>
<li><p><strong>Corollary</strong> DKW</p>
<p>![image-20191031155626864](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191031155626864.png)</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: operation.</p>
<p>![image-20191015161350400](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015161350400.png)</p>
</li>
</ul>
<h5 id="mono-layer-a-special-classifier-3-5">1.2.3.2.7. mono layer (a special classifier)(3-5)</h5><ul>
<li><p><strong>Def</strong>: see page 8 of class_3 lecture 5 </p>
<ul>
<li><p><strong>Theorm</strong>:  =&gt; bound of expected shatter coefficient</p>
<p>![image-20191023091839892](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023091839892.png)</p>
<ul>
<li><p><strong>Corollary</strong>: =&gt; convergence</p>
<p>![image-20191023091951058](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023091951058.png)</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="covering-number-2-7">1.2.3.2.8. covering number (2-7)</h5><ul>
<li><p><strong>Def</strong>: covering number (of a class of functions)</p>
<p>![image-20191015161821714](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015161821714.png)</p>
<p>![image-20191015161827731](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015161827731.png)</p>
</li>
<li><p><strong>Def</strong>: metric entropy </p>
<p>![image-20191015161845949](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015161845949.png)</p>
</li>
<li><p><strong>Def</strong>: totally bounded<img src="/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015161855035.png" alt="image-20191015161855035" style="zoom:50%;"></p>
</li>
<li><p><strong>Def</strong>: another entropy </p>
<p>![image-20191015161925184](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015161925184.png)</p>
<p>example:</p>
<p>![image-20191015162007623](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015162007623.png)</p>
<p>proof:<br>![image-20191015162014889](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015162014889.png)</p>
<p>![image-20191015162020934](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015162020934.png)</p>
<p>more examples:</p>
<p>![image-20191015162039271](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015162039271.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: =&gt; entropy retionalship</p>
<p>![image-20191015161939973](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015161939973.png)</p>
</li>
</ul>
<h3 id="P-Glivenko-Cantelli">1.2.4. P -Glivenko-Cantelli</h3><ul>
<li><p><strong>Lemma</strong>: ball covering lemma (2-7)</p>
<p>![image-20191015162115400](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015162115400.png)</p>
</li>
<li><p><strong>Def</strong>: P -Glivenko-Cantelli </p>
<p><strong>Usage</strong>: this is the goal of 1.2.3.2.4 if we recall.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g96ml75k6hj30nl02gmx7.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: envelope </p>
<p>![image-20191023000145242](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023000145242.png)</p>
<ul>
<li><p><strong>Theorm</strong>: =&gt; lim</p>
<p>![image-20191023000253706](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023000253706.png)</p>
<p>Note:</p>
<p>![image-20191023000301949](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023000301949.png)</p>
<p>proof:</p>
<p>![image-20191023000313947](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023000313947.png)</p>
<p>note:</p>
<p>![image-20191029125207884](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029125207884.png)</p>
<p>![image-20191029125224268](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029125224268.png)</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>: =&gt; CN and VC</p>
<p>![image-20191023000830993](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023000830993.png)</p>
</li>
</ul>
<h4 id="histogram-classifier-3-4">1.2.4.1. histogram classifier (3-4)</h4><ul>
<li><p><strong>Def</strong>: histo </p>
<p>![image-20191023001938977](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023001938977.png)</p>
<ul>
<li><p><strong>Qua</strong>: =&gt; bound </p>
<p>![image-20191023001951591](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023001951591.png)</p>
<p>fig </p>
<p>![image-20191023001958891](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023001958891.png)</p>
</li>
</ul>
</li>
</ul>
<h4 id="PAC-learning-amp-sample-complexity-3-4">1.2.4.2. PAC learning &amp; sample complexity (3-4)</h4><ul>
<li><p><strong>Def</strong>: pac </p>
<p>![image-20191023002030562](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023002030562.png)</p>
</li>
</ul>
<h4 id="zero-error-case-3-4">1.2.4.3. zero error case (3-4)</h4><ul>
<li><p><strong>Def</strong>: zero error </p>
<p>![image-20191023002105958](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023002105958.png)</p>
<ul>
<li><p><strong>Theorm</strong>: =&gt; zero bound </p>
<p>![image-20191023002127554](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023002127554.png)</p>
<p>proof: </p>
<p>![image-20191023002138178](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191023002138178.png)</p>
</li>
</ul>
</li>
</ul>
<h3 id="consistency-risk-3-6">1.2.5. consistency risk(3-6)</h3><ul>
<li><p><strong>Def</strong>: decomposition </p>
<p>![image-20191029152610501](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029152610501.png)</p>
<p>decomposite into 2 terms( estimation + approximation), esti means given a wide range of functions, the hn empirical can how effiencitly estimate the thing, and approximate is apparentl.</p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: UAP</p>
<p>![image-20191029153005411](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153005411.png)</p>
<p>note:</p>
<p>![image-20191029153012736](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153012736.png)</p>
<ul>
<li><p><strong>Theorm</strong>:  分段函数 =&gt;</p>
<p>![image-20191029153028874](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153028874.png)</p>
<p> example;</p>
<p>![image-20191029153332522](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153332522.png)</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: sieve estimator </p>
<p>![image-20191029153707104](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153707104.png)</p>
<p>![image-20191029153720547](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153720547.png)</p>
<p>![image-20191029153733061](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153733061.png)</p>
<ul>
<li><p><strong>Theorm</strong>:  =&gt; 普遍连续性（一定条件下收敛）</p>
<p>![ ](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153748953.png)</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>: =&gt; 不存在固定速率收敛</p>
<p>![image-20191029153817848](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153817848.png)</p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: box counting class </p>
<p>![image-20191029153837988](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153837988.png)</p>
<ul>
<li><p><strong>Theorm</strong>:  =&gt; 一定条件下的收敛速率</p>
<p>![image-20191029153846322](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191029153846322.png)</p>
</li>
</ul>
</li>
</ul>
<h2 id="alternative-learning-goals">1.3. alternative learning goals</h2><p>we know that the goal of learning is $Eloss(Y,F(X))$, but how can we do that, here’s some alternative learning goals that are approximations of original risk. </p>
<h3 id="maximum-likelihood">1.3.1. maximum likelihood</h3><ul>
<li><p><strong>Def</strong>: maximum likelihood</p>
<p><strong>Usage</strong>: turn to an alternative minimization goal</p>
<img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95npharqmj30ck04874b.jpg" style="zoom:33%;">



</li>
</ul>
<h3 id="probably-approximately-correct-1-13">1.3.2. probably approximately correct (1-13)</h3><ul>
<li><p><strong>Def</strong>: PAC</p>
<p><strong>Usage</strong>: turn to an alternative goal.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95o9tuhy7j315m07awg7.jpg" alt></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95o9zv0drj315y0560tu.jpg" alt></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95oaciywjj316y072wfk.jpg" alt></p>
<p>​    </p>
<ul>
<li><p><strong>Def</strong>: probability approximate corret condition </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95nkp8b07j31660ekwhc.jpg" alt="    "></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95nlmbv8fj316k092jsx.jpg" alt></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: PAC insights</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95o8uz3txj315u06qgna.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: PAC learnable </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95olftvxlj316s0dqacl.jpg" alt></p>
</li>
</ul>
<p>#perceptron algorithm</p>
<h2 id="perceptron-algorithim">1.4. perceptron algorithim</h2><ul>
<li><p><strong>Def</strong>: The perceptron algorithm performs pattern classification when F is the class of linear threshold functions.</p>
<p><img src="https://i.loli.net/2019/11/20/eJ6NBMAcbIR9mFO.png" alt></p>
<p><strong>Algo</strong>: algorithm of perceptron</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94uosvr98j30us09gt9p.jpg" alt></p>
<p><strong>Note</strong>: figure of perceptron</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94uoljm4lj30v00emta4.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Theorem</strong>: complexity of the algorithm to converge.</p>
<p><strong>Usage</strong>: result gives a bound on the number of steps in terms of some properties of the data. </p>
<p><img src="https://i.loli.net/2019/11/20/Qpn3gXHzTPF2aZY.png" alt="image.png"></p>
<p><strong>Proof</strong>: too long </p>
<p><strong>Note</strong>: perceptron complexity may not be linear, it is possible it do not terminate after a long time </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94uo4jzd8j30uk030aak.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: One important feature of this algorithm is that it only uses inner products of the data points. </p>
<p>The update step of the algorithm produces a wt which is a linear combination of the xi, so we write it as $wt = 􏰐nj=1 αjxj$ for $αj ∈ R$ and $∥α∥1 = 􏰐nj=1 |αj| ≤ t$. For this choice of $w t$, the prediction rule becomes</p>
</li>
</ul>
<ul>
<li><p>$$<br>  \hat{y}<em>i = sign(w_t ^{T}x _{i}) = sign( \sum</em>{j}^{}a _{j}x _{j} ^{T} x _{i})<br>$$</p>
<p>updates become (i is one of the misclassified points)<br>$$<br>a _{i} ^{(t+1)} = a _{i} ^{(t)} + y _{i}<br>$$<br><img src="https://i.loli.net/2019/11/20/tgpQOvDowBsfxHN.png" alt="image.png"></p>
<p>  <strong>Note</strong>:  from this quality we can see the inspiration of kernel, that we only need the inner product of xixj, with the quality of readiness of computing inner product after projection, we can use kernel to get a more complex model</p>
<p><img src="https://i.loli.net/2019/11/20/q68lQbYzNG9xjSs.png" alt="image.png"></p>
</li>
</ul>
<ul>
<li><p><strong>Lemma</strong>: linearly independent =&gt; seperatable data </p>
<p><img src="https://i.loli.net/2019/11/20/NcJWjmECne4zbg1.png" alt="image.png"></p>
<p><strong>Proof</strong>:</p>
<p>  <img src="https://i.loli.net/2019/11/20/5goRmWdDwpyv8hK.png" alt="image.png"></p>
<ul>
<li><p><strong>Theorem</strong> : The main theorem in this section shows that for any prediction rule (from the class of linear threshold functions), there is a probability distribution that is linearly separable, but for which the prediction rule does poorly when averaged over all training data sets. </p>
<p><strong>Usage</strong>: we can compute this lower bound, to estimate the risk for this threshold function.</p>
<p><img src="https://i.loli.net/2019/11/20/MtqP29VGAsvCU6B.png" alt="image.png"></p>
<p><strong>Proof</strong>: too long</p>
<p><strong>Note</strong> 1: see this bound as minimax lower bound, meaning that whatever $f _{n}$ you choose, there exists some part of the training dataset that yield result with lower bound.</p>
<p><img src="https://i.loli.net/2019/11/20/VqbT2vfYJE9oSH3.png" alt="image.png"></p>
<p><strong>Note</strong> 2: generalization using VC dimension.</p>
<p><img src="https://i.loli.net/2019/11/20/zdSptJbWMUu9DQm.png" alt="image.png"></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Theorem</strong>: If we restrict our attention to probability distributions that have a large margin, we can prove an upper bound for the risk of the perceptron algorithm: </p>
<p><img src="https://i.loli.net/2019/11/20/OzXTrZA4jmY9hVx.png" alt="image.png"></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94un7bhjsj30wc0byta5.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Theorm</strong>: In the above theorem, we were maximizing over all probability distributions.  If we restrict the maximization to be over those probability distributions having a large margin we can obtain a better lower bound: </p>
<p><img src="https://i.loli.net/2019/11/20/HR7Fxa9ZECuMVeS.png" alt="image.png"></p>
<p><strong>Proof</strong>: </p>
<p><img src="https://i.loli.net/2019/11/20/h8gfUSourM4qYQw.png" alt="image.png"></p>
</li>
</ul>
<h2 id="support-vector-machine">1.5. support vector machine</h2><h3 id="basic-SVM">1.5.1. basic SVM</h3><ul>
<li><p><strong>Def</strong>: support vector machine</p>
<p><strong>Usage</strong>: special form of perceptron where the distance is maximized </p>
<p><img src="https://s2.ax1x.com/2019/11/20/MWp8JJ.png" alt="MWp8JJ.png"></p>
<p><strong>Note</strong>: </p>
<img src="https://s2.ax1x.com/2019/11/20/MWpAiQ.png" alt="MWpAiQ.png" style="zoom:89%;">



</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: basic transformations</p>
<p>trans: other form $\left |  w\right |=1$ </p>
<p><img src="https://s2.ax1x.com/2019/11/20/MWpfw8.png" alt="MWpfw8.png"></p>
<p>trans: other form  $\left |  w\right |=1/ \gamma$</p>
<p><img src="https://s2.ax1x.com/2019/11/20/MWpOmV.png" alt="MWpOmV.png"></p>
<p>lagrange function</p>
<p><img src="https://i.loli.net/2019/11/20/pzyisx7Ag5mFQGv.png" alt="image.png"></p>
<p>get lagrange dual function</p>
<p><img src="https://i.loli.net/2019/11/20/qVtT6Qz1an5b3mK.png" alt="image.png"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94ume9k1hj30ts024a9y.jpg" alt></p>
<p>interpret lagrange function</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94ullkwx7j30w209qq4b.jpg" alt></p>
<p>lagrange dual function </p>
<p><img src="https://i.loli.net/2019/11/20/UbqFniyShgl627Y.png" alt="image.png"></p>
<p>dual problem </p>
<p><img src="https://i.loli.net/2019/11/20/Jg5KwYC4clsp1LO.png" alt="image.png"></p>
<p>recall slackenss for dual problem, this show that the those with ai(penalty loss) $\neq$ 0, are exactly those in the margins.</p>
<p><img src="https://i.loli.net/2019/11/20/SwgJqitobc2Xvku.png" alt="image.png"></p>
<p>recall the kernel stuff, we can use kernel to efficientlly solve this, for more kernel stuff turn to 2.2.2</p>
<p><img src="https://i.loli.net/2019/11/20/IrRWNKDMTS9mn6l.png" alt="image.png"></p>
</li>
</ul>
<h3 id="kernel-SVM">1.5.2. kernel SVM</h3><ul>
<li><p><strong>Def</strong>: dual problem &amp; kernel function</p>
<p>dual problem (only inner products determines solution)    <img src="https://i.loli.net/2019/11/20/Jg5KwYC4clsp1LO.png" alt="image.png"></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: kernel function can reduce complexity of dual problem.( further discussion can be find in linera algebra)</p>
<p><strong>Usage</strong>: 由此看出，即使没有kernel，只要找到映射关系，我们仍然可以实现低维空间映射到高维空间，进而通过高维向量内积运算来寻找最佳分割超平面。但是，kernel的引入，降低了向量内积运算的计算复杂度。无论我们映射到几维空间，我们只要把原有维度代入核函数，就能等价于高维上的内积运算。极端的情况下，特征空间映射到了无穷维度空间，如果没有核函数，根本无法计算出映射后的向量内积。</p>
<p>（映射到新的特征空间后的内积=原空间核函数）</p>
<p><a href="https://blog.csdn.net/zhangjun2915/article/details/79261368" target="_blank" rel="noopener">https://blog.csdn.net/zhangjun2915/article/details/79261368</a></p>
<p>k(xi, xj) is the kernel function of inner product of xi, xj</p>
</li>
</ul>
<ul>
<li><p><strong>Example</strong>: polynomial kernel</p>
<p><img src="https://i.loli.net/2019/11/20/WFjVfnO7pPeCmqd.png" alt="image.png"></p>
</li>
<li><p><strong>Example</strong>: gaussian kernel </p>
<p><img src="https://i.loli.net/2019/11/20/H13oW6M2znwQlKY.png" alt="image.png"></p>
</li>
</ul>
<h3 id="primal-SVM">1.5.3. primal SVM</h3><ul>
<li><p><strong>Def</strong>:  primal SVM, more natural way</p>
<p><img src="https://i.loli.net/2019/11/20/ksrwUoluGiF7jMI.png" alt="image.png"></p>
<p>lagrangian functiion </p>
<p><img src="https://i.loli.net/2019/11/20/eJiRtwo5M9AEkDN.png" alt="image.png"></p>
<p>getting lagranian dual function </p>
<p><img src="https://i.loli.net/2019/11/20/oYLf9tT3VOjEwUW.png" alt="image.png"></p>
<p>lagrangain dual function </p>
<p><img src="https://i.loli.net/2019/11/20/IyrRtMfzo4mJelU.png" alt="image.png"></p>
<p>dual problem</p>
<p><img src="https://i.loli.net/2019/11/20/Wbrua1oidJILVPp.png" alt="image.png"></p>
<p>this problem can actually be solved by hand: first solve $\beta = \sqrt{1/4 \left | \sum_{i}^{}\lambda _{i}y _{i } x _{i}\right |}$, then we get the following </p>
<p><img src="https://i.loli.net/2019/11/20/8CZfKqxytmOoYih.png" alt="image.png"></p>
<p>interpreting results</p>
<p><img src="https://i.loli.net/2019/11/20/WUvX9rTzie2xRn4.png" alt="image.png"></p>
</li>
</ul>
<h3 id="soft-C-SVM">1.5.4. soft C-SVM</h3><ul>
<li><p><strong>Def</strong>:  soft SVM</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kd7xe38j30sc024jrf.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: basic transform</p>
<p>trans: change |x&lt;1| to (1-x)+ , basiclly is the same .</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kdj455cj30ok02q3ym.jpg" alt></p>
<p>trans: slack variable </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kdp69btj30rs046aac.jpg" alt></p>
<p>lagranrian function =&gt; dual lagranian function  </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kemgiihj30rk08gdgt.jpg" alt></p>
<p>dual problem </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kev03x5j30pg036t8v.jpg" alt></p>
<p>complementary slackness conditions : This implies that all the support vectors with y = 1 lie in the half-plane {x : xT w ≤ 1}. </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94kfc3xu7j30ni03oq35.jpg" alt></p>
<p>insights from above: </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94l67o489j314q088wgp.jpg" alt></p>
<p>choose c</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94l6l7zfcj316e0380tf.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: interpreting in another way( loss function + regularization)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94llq6xidj315w03ct92.jpg" alt></p>
</li>
</ul>
<h3 id="soft-nu-SVM">1.5.5. soft $\nu$-SVM</h3><ul>
<li><p><strong>Def</strong>: a more interpretable way, since $\nu$ is more easy to set.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lf89bzoj314a05gwey.jpg" alt></p>
<ul>
<li><p><strong>Qua</strong>: basic transition </p>
<p>slack variables </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lfwvlcxj315607y0tg.jpg" alt></p>
<p>lagrange dual function </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lgbmkh1j30wi03oglu.jpg" alt></p>
<p>dual problem </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lgoido3j30y208oq3v.jpg" alt></p>
<p>insights for slackness</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94lhpmmmmj316804wt9z.jpg" alt></p>
</li>
<li><p><strong>Qua</strong>: interpretation of $\nu$ : we can interpret $nu$ as being approximately the fraction of data that are margin errors. </p>
<p>![image-20191120164148468](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191120164148468.png)</p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94litz5uxj316604g3zx.jpg" alt></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: $\nu$ and C SVM are the same </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94ljbz53fj316o02gt99.jpg" alt></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g94ljika20j317a0lon06.jpg" alt></p>
</li>
</ul>
<h3 id="e-sensitive-SVM-1-10">1.5.6. e-sensitive SVM (1-10)</h3><ul>
<li><p><strong>Def</strong>: a relaxation of loss function</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jkwn25kj31d60hajuf.jpg" alt></p>
</li>
</ul>
<h1 id="bayes-algorithm">2. bayes algorithm</h1><h2 id="bayes-algorithm-1">2.1. bayes algorithm</h2><ul>
<li><p><strong>Def</strong>:</p>
<p>![image-20191015164005026](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015164005026.png)</p>
<ul>
<li><p><strong>Qua</strong>: =&gt; same as before</p>
<p>![image-20191015164040905](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015164040905.png)</p>
<p>notes:</p>
<p>![image-20191015164149159](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015164149159.png)</p>
<p>![image-20191015164157450](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015164157450.png)</p>
<p>![image-20191015164203222](/Users/huangbenson/Library/Application Support/typora-user-images/image-20191015164203222.png)</p>
</li>
</ul>
</li>
</ul>
<h2 id="bayes-analysis-1-10">2.2. bayes analysis(1-10)</h2><ul>
<li><p><strong>Def</strong>: using kernel to interpretate</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jk8garjj31ca0ma79u.jpg" alt></p>
</li>
</ul>
<h1 id="regression-algorithm">3. regression algorithm</h1><h2 id="kernel-ridge-regression-1-10">3.1. kernel ridge regression (1-10)</h2><ul>
<li><p><strong>Def</strong>: kernel regression </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jg6n3h0j31c20fgtbh.jpg" alt></p>
<p><strong>Note</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jgg2rpcj317g0eutal.jpg" alt></p>
</li>
</ul>
<h2 id="logistic-regression-1-13">3.2. logistic regression (1-13)</h2><ul>
<li><p><strong>Def</strong>: logistic regression </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95mj6tnn0j318o0640w1.jpg" alt></p>
<p><strong>Algorithm</strong>: maximum likelihood  </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95mjwxpazj315y0dc0v5.jpg" alt></p>
</li>
</ul>
<h1 id="ensemble-algorithm">4. ensemble algorithm</h1><ul>
<li><p><strong>Def</strong>: ensemble methods</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jox8hk9j311i0u042p.jpg" alt></p>
</li>
</ul>
<h2 id="adaboost-1-12-1-13">4.1. adaboost (1-12, 1-13)</h2><ul>
<li><p><strong>Def</strong>: adaboost</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jqrjkmjj315m084dh1.jpg" alt></p>
<p><strong>Algorithm</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jrlyyqij317c0a8q5c.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Theorem</strong>: upper bound for Em-Ft-loss of adaboost</p>
<p><strong>Usage</strong>: ensuring the performace.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jrxmf2cj314i092wfg.jpg" alt></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95kzuorryj313c0mwtbm.jpg" alt></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95l02cd6kj31340mkdic.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Theorem</strong>: for standardized F</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95js9pkqkj316k08cq4q.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Theorem</strong>: there exist upper bound for loss function, if conditions are met.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95l4x2rifj316a05ugml.jpg" alt></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95l513c30j315i0f0q57.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Theorem</strong>: use gradient decent to explain adaboost </p>
<p><strong>Usage</strong>: iteratively solving adaboost is equivalent to minimizing the true loss function of $e ^{-YF _{T}(x)}$</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jsuxibxj316205wgml.jpg" alt></p>
<p><strong>Proof</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95lgbda3bj319u0h6dj1.jpg" alt></p>
<p><strong>Note</strong>: loss function: For every t from 1 to T, we can expand the E(exp(-YX)) thing, and we can see that adaboost is minimizing Eexp(YFT(X)) at every step, thus the we are using step-wise gradient decent to optimize the Eexp(-YX). </p>
<p>The whole picture: So this is the idea of adaboost, we choose fT to minimize eT as a step-wise gradient descent, then we find out we can see adaboost as E(-YX) in whole, so we choose $\alpha T$ to make that happen.</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95ldb2stkj31ac05g40g.jpg" alt></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95m3zu4mkj316c054mxx.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: similarity to logistic regression (1-13)</p>
<p>using taylor expansion we can see that the first elements are the same ( $ln(1+e ^{-2a})+1-ln2$ &amp; $e(-a)$)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95mln63k6j316407o3zu.jpg" alt></p>
<p>e(-a) is above</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95n9q6myzj30oc0dy0tu.jpg" alt></p>
<p>differences: 1) e(-a) are larger 2) adaboost is approximation of max-likelihood logistic regression with larger penalty. </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95nakqg24j316i09cdi1.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Qua</strong>: PAC related </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95o80ulhcj315g0f643c.jpg" alt></p>
</li>
</ul>
<ul>
<li><p><strong>Def</strong>: generalized adaboost:</p>
<p><strong>Usage</strong>: in adaboost, we use exp(-YX) as loss, here we can have different options and still implement the step-wise adaboost core idea: we see J(F) as the loss, F is the variable, and each step we take  $F+\alpha _{t}f _{t}$  </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jtgz619j31880kmad7.jpg" alt></p>
<p>recall: (convex optimization)</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g95luzezzcj31b00d0dml.jpg" alt></p>
<p><strong>Algorithm</strong>: </p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g95jtonm5mj316u0by0vb.jpg" alt></p>
</li>
</ul>

      
    </div>
    
    
    

    <div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>Title:</span><a href="/2019/11/19/stats_theory/">Statistical Learning Theory</a></p>
  <p><span>Author:</span><a href="/" title=" Benson 的personal blog">Benson</a></p>
  <p><span>PTime:</span>2019/11/19 - 12:11</p>
  <p><span>LUpdate:</span>2019/11/22 - 10:11</p>
  <p><span>Link:</span><a href="/2019/11/19/stats_theory/" title="Statistical Learning Theory">https://steinsgate9.github.io/2019/11/19/stats_theory/</a>
    <span class="copy-path"  title="click to copy link"><i class="fa fa-clipboard" data-clipboard-text="https://steinsgate9.github.io/2019/11/19/stats_theory/"  aria-label="copy done！"></i></span>
  </p>
  <p><span>Protocal:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)</a> Please keep the original link and author.</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: 'copy done',
          icon: "success", 
          showConfirmButton: true
          });
    });
    });  
</script>

      
    </div>
    
    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="Benson WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.png" alt="Benson Alipay"/>
        <p>Alipay</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/stats/" rel="tag"># stats</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/11/19/testmath/" rel="next" title="testmath">
                <i class="fa fa-chevron-left"></i> testmath
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/11/19/c++-%5Bb%5D/" rel="prev" title="C++">
                C++ <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- Go to www.addthis.com/dashboard to customize your tools -->
<div class="addthis_inline_share_toolbox">
  <script type = "text/javascript" src = "//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5dd409321289b452" async = "async" ></script>
</div>

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80NzYxNi8yNDExNA"></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://tva1.sinaimg.cn/large/006y8mN6gy1g96p07mbexj30uf0u0npd.jpg"
                alt="Benson" />
            
              <p class="site-author-name" itemprop="name">Benson</p>
              <p class="site-description motion-element" itemprop="description">Benson's personal blog, including stats, cs, math, among others.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/SteinsGate9" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="bensonuouououow@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-globe"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://twitter.com/bensonuouououo" target="_blank" title="Twitter">
                      
                        <i class="fa fa-fw fa-globe"></i>Twitter</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.instagram.com/bensonuouououo/" target="_blank" title="Instagram">
                      
                        <i class="fa fa-fw fa-globe"></i>Instagram</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.alloyteam.com/nav/" title="Web前端导航" target="_blank">Web前端导航</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.chuangzaoshi.com/code" title="创造狮导航" target="_blank">创造狮导航</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.36zhen.com/t?id=3448" title="前端书籍资料" target="_blank">前端书籍资料</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://e.xitu.io/" title="掘金酱" target="_blank">掘金酱</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.v2ex.com/" title="V2EX" target="_blank">V2EX</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.v2ex.com/" title="印记中文" target="_blank">印记中文</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#generalized-expected-risk"><span class="nav-text">1. generalized expected risk</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#learning-algorithm-amp-loss-functions-1-1-3-1"><span class="nav-text">1.1. learning algorithm &amp; loss functions (1-1, 3-1)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#loss-functions"><span class="nav-text">1.2. loss functions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#E-f-loss-1-1-1-2-1-3-1-7-3-2"><span class="nav-text">1.2.1. E-f-loss (1-1, 1-2,  1-3, 1-7, 3-2)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#E-f-loss"><span class="nav-text">1.2.1.1. E-f-loss</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#E-f-newloss-1-6-1-7"><span class="nav-text">1.2.2. E-f-newloss (1-6, 1-7)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Em-f-loss-1-13-3-3"><span class="nav-text">1.2.3. Em-f-loss (1-13, 3-3)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Em-f-loss-1-2-1-13-3-3"><span class="nav-text">1.2.3.1. Em-f-loss (1-2, 1-13, 3-3)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#empirical-processing-theory"><span class="nav-text">1.2.3.2. empirical processing theory</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#empirical-distribution-function"><span class="nav-text">1.2.3.2.1. empirical distribution function</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Glivenko-Cantelli-theory-1-16"><span class="nav-text">1.2.3.2.2. Glivenko-Cantelli theory (1-16)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#symmetrization-2-5"><span class="nav-text">1.2.3.2.3. symmetrization (2-5)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#uniform-convergence-amp-uniform-law-of-large-numbers"><span class="nav-text">1.2.3.2.4. uniform convergence &amp; uniform law of large numbers</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#vc-class-and-stuff"><span class="nav-text">1.2.3.2.5. vc class and stuff</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#covering-number"><span class="nav-text">1.2.3.2.5.1. covering number</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#vc-theory-for-sets-3-5"><span class="nav-text">1.2.3.2.6. vc theory for sets(3-5)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#mono-layer-a-special-classifier-3-5"><span class="nav-text">1.2.3.2.7. mono layer (a special classifier)(3-5)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#covering-number-2-7"><span class="nav-text">1.2.3.2.8. covering number (2-7)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#P-Glivenko-Cantelli"><span class="nav-text">1.2.4. P -Glivenko-Cantelli</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#histogram-classifier-3-4"><span class="nav-text">1.2.4.1. histogram classifier (3-4)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PAC-learning-amp-sample-complexity-3-4"><span class="nav-text">1.2.4.2. PAC learning &amp; sample complexity (3-4)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#zero-error-case-3-4"><span class="nav-text">1.2.4.3. zero error case (3-4)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#consistency-risk-3-6"><span class="nav-text">1.2.5. consistency risk(3-6)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#alternative-learning-goals"><span class="nav-text">1.3. alternative learning goals</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#maximum-likelihood"><span class="nav-text">1.3.1. maximum likelihood</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#probably-approximately-correct-1-13"><span class="nav-text">1.3.2. probably approximately correct (1-13)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#perceptron-algorithim"><span class="nav-text">1.4. perceptron algorithim</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#support-vector-machine"><span class="nav-text">1.5. support vector machine</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#basic-SVM"><span class="nav-text">1.5.1. basic SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kernel-SVM"><span class="nav-text">1.5.2. kernel SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#primal-SVM"><span class="nav-text">1.5.3. primal SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#soft-C-SVM"><span class="nav-text">1.5.4. soft C-SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#soft-nu-SVM"><span class="nav-text">1.5.5. soft $\nu$-SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#e-sensitive-SVM-1-10"><span class="nav-text">1.5.6. e-sensitive SVM (1-10)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#bayes-algorithm"><span class="nav-text">2. bayes algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#bayes-algorithm-1"><span class="nav-text">2.1. bayes algorithm</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bayes-analysis-1-10"><span class="nav-text">2.2. bayes analysis(1-10)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#regression-algorithm"><span class="nav-text">3. regression algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#kernel-ridge-regression-1-10"><span class="nav-text">3.1. kernel ridge regression (1-10)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#logistic-regression-1-13"><span class="nav-text">3.2. logistic regression (1-13)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ensemble-algorithm"><span class="nav-text">4. ensemble algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#adaboost-1-12-1-13"><span class="nav-text">4.1. adaboost (1-12, 1-13)</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2015 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Benson</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      total visitors
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      people
    </span>
  

  
    <span class="site-pv">
      total read
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      times
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.4"></script>



  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.staticfile.org/MathJax/MathJax-2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
